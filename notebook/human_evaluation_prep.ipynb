{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "779f0298",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from datasets import load_from_disk, load_dataset, load_metric\n",
    "import pickle\n",
    "from rouge_score import rouge_scorer\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from collections import Counter\n",
    "import string\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35865051",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from dataset import CitationTextGenerationRAGDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c49c13a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = set(stopwords.words('english')).union(set(string.punctuation))\n",
    "rouge = load_metric(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13e41348",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_stop(text):\n",
    "    cleaned = []\n",
    "    for word in text.split():\n",
    "        if word not in stops:\n",
    "            cleaned.append(word)\n",
    "    return \" \".join(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff62ac5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop(words):\n",
    "    cleaned = []\n",
    "    for word in words:\n",
    "        word = word.lower()\n",
    "        if word not in stops:\n",
    "            cleaned.append(word)\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f569066",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_citation_marks(text, citations):\n",
    "    for citation in citations.split(\"#\"):\n",
    "        text = text.replace(\"\\n\",\" \").replace(citation,\"\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f193614",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_words(cited_text, highlights):\n",
    "    processed_words = []\n",
    "    for word in word_tokenize(cited_text):\n",
    "        if word.lower() in highlights:\n",
    "            word = \"<b><i>\"+word+\"</i></b>\"\n",
    "        processed_words.append(word)\n",
    "    return \" \".join(processed_words) + \"<br>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75314034",
   "metadata": {},
   "outputs": [],
   "source": [
    "passages_path = os.path.join(\"cited_text_embeddings_sentence_better\", \"cited_papers\")\n",
    "sentence_cited_dataset = load_from_disk(passages_path)\n",
    "passages_path = \"cited_text_embeddings_citation_mark/cited_papers\"\n",
    "paragraph_cited_dataset = load_from_disk(passages_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1002458",
   "metadata": {},
   "outputs": [],
   "source": [
    "exception = '173188413_1_0_2@52113465'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27ed9528",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_files = {\n",
    "    \"fid_abstract\": \"FiD_CTS_RAG_span_generation_retrieved_abstract.jsonl\",\n",
    "    #\"led_abstract\": \"LED_abstract_citation_span_generation.jsonl\",\n",
    "    \"fid_context\": \"FiD_CTS_RAG_span_generation_sentence_pre_retrieval.jsonl\",\n",
    "    #\"led_context\":\"LED_sentence_CTS_citation_span_generation.jsonl\",\n",
    "    \"fid_oracle\":\"FiD_CTS_RAG_span_generation_sentence_oracle.jsonl\",\n",
    "    #\"led_oracle\":\"LED_oracle_sentence_CTS_citation_span_generation.jsonl\",\n",
    "    \"fid_keyword\":\"FiD_CTS_RAG_span_generation_sentence_keyword.jsonl\",\n",
    "    #\"led_keyword\": \"keyword_sentence_CTS_citation_span_generation.jsonl\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1de2ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_outputs = {}\n",
    "for config, file in prediction_files.items():\n",
    "    outputs = []\n",
    "    with open(file) as f:\n",
    "        for line in f:\n",
    "            outputs.append(json.loads(line))\n",
    "    all_outputs[config] = outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab26e3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "integrated_predictions = {}\n",
    "for config, outputs in all_outputs.items():\n",
    "    for example in outputs:\n",
    "        this_example = integrated_predictions.get(example[\"id\"],{})\n",
    "        if \"led_\" in config:\n",
    "            pred = example[\"prediction\"][0].replace(\"\\n\",\" \")\n",
    "        else:\n",
    "            pred = example[\"prediction\"].replace(\"\\n\",\" \")\n",
    "        this_example[config] = pred\n",
    "        integrated_predictions[example[\"id\"]] = this_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aeb0cf8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fid_abstract': 'Bao et al. (2018) proposed a generative model to generate a natural language sentence describing a',\n",
       " 'fid_context': 'Bao et al. (2018) proposed a generative model to generate a natural language sentence describing a table.',\n",
       " 'fid_oracle': 'Bao et al. (2018) proposed a table-aware decoder to copy from the input.',\n",
       " 'fid_keyword': 'Bao et al. (2018) proposed a copy mechanism that can copy from both the cells and attributes.'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "integrated_predictions[\"202766392_0_0_5@19099243\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0bf3c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract_ids = {example['id']: example['retrieved_doc_ids'] for example in all_outputs[\"fid_abstract\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59e2fcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_ids = {example['id']: example['retrieved_doc_ids'] for example in all_outputs[\"fid_context\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d57cbf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "oracle_ids = {example['id']: example['retrieved_doc_ids'] for example in all_outputs[\"fid_oracle\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20605bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_ids = {example['id']: example['retrieved_doc_ids'] for example in all_outputs[\"fid_keyword\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b4ef352",
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts = {}\n",
    "for example in all_outputs[\"fid_oracle\"]:\n",
    "    context = example['source'].split(\"[E_Dominant]\")[-1].split(\"[E_Reference]\")[-1]\n",
    "    context = context.split(\"[Dominant]\")[0].replace(\"\\n\",\" \").strip()\n",
    "    contexts[example['id']] = context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a4f0072f",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = {}\n",
    "for example in all_outputs[\"fid_oracle\"]:\n",
    "    target = example['target']\n",
    "    targets[example['id']] = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8b95b1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "citations = {}\n",
    "for example in all_outputs[\"fid_oracle\"]:\n",
    "    citations[example['id']] = example['citations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "75a0efd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "integrated_outputs = {}\n",
    "for ID, preds in integrated_predictions.items():\n",
    "    preds[\"target\"] = targets[ID]\n",
    "    integrated_outputs[ID] = {\n",
    "        \"predictions\": preds,\n",
    "        \"context\": contexts[ID],\n",
    "        \"abstract_ids\": abstract_ids[ID],\n",
    "        \"context_ids\": context_ids[ID],\n",
    "        \"oracle_ids\": oracle_ids[ID],\n",
    "        \"keyword_ids\": keyword_ids[ID],\n",
    "        \"citations\": citations[ID],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "14955f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = [\n",
    "    \"target\",\n",
    "    \"fid_abstract\",\n",
    "    #\"led_abstract\",\n",
    "    \"fid_context\",\n",
    "    #\"led_context\",\n",
    "    \"fid_oracle\",\n",
    "    #\"led_oracle\",\n",
    "    \"fid_keyword\",\n",
    "    #\"led_keyword\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "673157b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"human_evaluation_html/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67889d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "del integrated_outputs[exception]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51295031",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6726e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sampled_ids = random.sample(list(integrated_outputs.keys()),N)\n",
    "all_sampled_ids = sorted(all_sampled_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2460d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_ids = all_sampled_ids[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52905b17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "order_ids = {}\n",
    "for ID in tqdm(sampled_ids):\n",
    "    output = integrated_outputs[ID]\n",
    "    concat_preds = []\n",
    "    for k,v in output[\"predictions\"].items():\n",
    "        concat_preds.append(v)\n",
    "    citation_marks = output[\"citations\"]\n",
    "    pred = \" \".join(concat_preds)\n",
    "    highlights = set(remove_stop(word_tokenize(remove_citation_marks(pred, citation_marks))))\n",
    "    \n",
    "    retrieved_sentence_ids = set([])\n",
    "    for name in [\"context_ids\", \"oracle_ids\", \"keyword_ids\"]:\n",
    "        for idx in output[name]:\n",
    "            if idx >= 0:\n",
    "                retrieved_sentence_ids.add(idx)\n",
    "    retrieved_sentence_ids = sorted(list(retrieved_sentence_ids))\n",
    "    sentence_CTS = []\n",
    "    for si in retrieved_sentence_ids:\n",
    "        cited_text = sentence_cited_dataset[si][\"text\"]\n",
    "        author = sentence_cited_dataset[si][\"title\"]\n",
    "        highlighted_sentence = highlight_words(cited_text, highlights)\n",
    "        sentence_CTS.append(author + \" ## \" + highlighted_sentence)\n",
    "    output[\"sentence_CTS\"] = sentence_CTS\n",
    "    \n",
    "    retrieved_paragraph_ids = set([])\n",
    "    for idx in output[\"abstract_ids\"]:\n",
    "        if idx >= 0:\n",
    "            retrieved_paragraph_ids.add(idx)\n",
    "    retrieved_paragraph_ids = sorted(list(retrieved_paragraph_ids))\n",
    "    abstracts = []\n",
    "    for pi in retrieved_paragraph_ids:\n",
    "        cited_text = paragraph_cited_dataset[pi][\"text\"]\n",
    "        author = paragraph_cited_dataset[pi][\"title\"]\n",
    "        highlighted_abstract = highlight_words(cited_text, highlights)\n",
    "        abstracts.append(author + \" ## \" +highlighted_abstract)\n",
    "    output[\"abstracts\"] = abstracts\n",
    "    config_indices = [i for i in range(len(configs))]\n",
    "    random.shuffle(config_indices)\n",
    "    shuffle_order = \"\".join([str(i) for i in config_indices])\n",
    "    order_ids[ID] = config_indices\n",
    "    with open(base_dir + ID+\".html\",\"w\") as f:\n",
    "        f.write(\"Span ID: \"+ID+\"<br>\")\n",
    "        f.write(\"<h2>Context (Up to 2 sentences before the target citation):</h2>\")\n",
    "        f.write(output[\"context\"])\n",
    "        f.write(\"<h2>Randomized System Outputs:</h2>\")\n",
    "        for i, idx in enumerate(config_indices):\n",
    "            config = configs[idx]\n",
    "            f.write(str(i+1)+\". \"+output[\"predictions\"][config]+\"<br>\")\n",
    "        f.write(\"<h2>Cited Abstracts:</h2>\")\n",
    "        for abstract in abstracts:\n",
    "            f.write(abstract)\n",
    "        f.write(\"<h2>Retrieved Body Sentences:</h2>\")\n",
    "        for cts in sentence_CTS:\n",
    "            f.write(cts)\n",
    "with open(\"group2_configs.json\",\"w\") as f:\n",
    "    json.dump(order_ids,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d0aadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"YourName.csv\",\"w\") as f:\n",
    "    f.write(\",\".join([\"id\",\"system#\",\"fluency\",\"coherence\",\"relevance\",\"overall\"])+\"\\n\")\n",
    "    for ID in sampled_ids:\n",
    "        for i in range(len(configs)):\n",
    "            f.write(\",\".join([ID,str(i+1),\"\",\"\",\"\",\"\"])+\"\\n\")\n",
    "        f.write(\",\".join([\"\",\"\",\"\",\"\",\"\",\"\"])+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bb1a5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d3d4962e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"group1_configs.json\") as f:\n",
    "    group_config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5e082314",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"group2_configs.json\") as f:\n",
    "    group_config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba12228e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ID, config_indices in tqdm(group_config.items()):\n",
    "    output = integrated_outputs[ID]\n",
    "    concat_preds = []\n",
    "    for k,v in output[\"predictions\"].items():\n",
    "        concat_preds.append(v)\n",
    "    citation_marks = output[\"citations\"]\n",
    "    pred = \" \".join(concat_preds)\n",
    "    highlights = set(remove_stop(word_tokenize(remove_citation_marks(pred, citation_marks))))\n",
    "    \n",
    "    retrieved_sentence_ids = set([])\n",
    "    for name in [\"context_ids\", \"oracle_ids\", \"keyword_ids\"]:\n",
    "        for idx in output[name]:\n",
    "            if idx >= 0:\n",
    "                retrieved_sentence_ids.add(idx)\n",
    "    retrieved_sentence_ids = sorted(list(retrieved_sentence_ids))\n",
    "    sentence_CTS = []\n",
    "    for si in retrieved_sentence_ids:\n",
    "        cited_text = sentence_cited_dataset[si][\"text\"]\n",
    "        author = sentence_cited_dataset[si][\"title\"]\n",
    "        highlighted_sentence = highlight_words(cited_text, highlights)\n",
    "        sentence_CTS.append(author + \" ## \" + highlighted_sentence)\n",
    "    output[\"sentence_CTS\"] = sentence_CTS\n",
    "    \n",
    "    retrieved_paragraph_ids = set([])\n",
    "    for idx in output[\"abstract_ids\"]:\n",
    "        if idx >= 0:\n",
    "            retrieved_paragraph_ids.add(idx)\n",
    "    retrieved_paragraph_ids = sorted(list(retrieved_paragraph_ids))\n",
    "    abstracts = []\n",
    "    for pi in retrieved_paragraph_ids:\n",
    "        cited_text = paragraph_cited_dataset[pi][\"text\"]\n",
    "        author = paragraph_cited_dataset[pi][\"title\"]\n",
    "        highlighted_abstract = highlight_words(cited_text, highlights)\n",
    "        abstracts.append(author + \" ## \" +highlighted_abstract)\n",
    "    output[\"abstracts\"] = abstracts\n",
    "\n",
    "    shuffle_order = \"\".join([str(i) for i in config_indices])\n",
    "    with open(base_dir + ID+\".html\",\"w\") as f:\n",
    "        f.write(\"Span ID: \"+ID+\"$\"+\"<br>\")\n",
    "        f.write(\"<h2>Context (Up to 2 sentences before the target citation):</h2>\")\n",
    "        f.write(output[\"context\"])\n",
    "        f.write(\"<h2>Randomized System Outputs:</h2>\")\n",
    "        for i, idx in enumerate(config_indices):\n",
    "            config = configs[idx]\n",
    "            if config == \"target\":\n",
    "                f.write(\"<b><i>\"+str(i+1)+\". \"+output[\"predictions\"][config]+\"</i></b><br>\")\n",
    "            else:\n",
    "                f.write(str(i+1)+\". \"+output[\"predictions\"][config]+\"<br>\")\n",
    "        f.write(\"<h2>Cited Abstracts:</h2>\")\n",
    "        for abstract in abstracts:\n",
    "            f.write(abstract)\n",
    "        f.write(\"<h2>Retrieved Body Sentences:</h2>\")\n",
    "        for cts in sentence_CTS:\n",
    "            f.write(cts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e13b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(base_dir + \"YourName_target.csv\",\"w\") as f:\n",
    "    f.write(\",\".join([\"id\",\"system#\",\"fluency\",\"coherence\",\"relevance\",\"overall\"])+\"\\n\")\n",
    "    for ID, config_indices in group_config.items():\n",
    "        for i in range(len(configs)):\n",
    "            f.write(\",\".join([ID+\"$\",str(i+1),\"\",\"\",\"\",\"\"])+\"\\n\")\n",
    "        f.write(\",\".join([\"\",\"\",\"\",\"\",\"\",\"\"])+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca3ee24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8bdd420a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"group1_configs.json\") as f:\n",
    "    group_config = json.load(f)\n",
    "with open(\"group2_configs.json\") as f:\n",
    "    group2_config = json.load(f)\n",
    "group_config.update(group2_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "76b07ff9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'102350797_0_0_1@3144258': [1, 3, 4, 0, 2],\n",
       " '128350532_2_0_2@13335042': [3, 4, 0, 2, 1],\n",
       " '166228482_2_0_3@8140780': [4, 3, 0, 1, 2],\n",
       " '173188413_2_0_0@44130060': [0, 2, 4, 1, 3],\n",
       " '173990267_1_0_4@5068376': [0, 4, 3, 1, 2],\n",
       " '174798410_0_0_0@21700944': [3, 0, 4, 2, 1],\n",
       " '174799580_0_0_4@52068673': [0, 4, 2, 1, 3],\n",
       " '184482991_3_0_0@3936688': [4, 1, 2, 0, 3],\n",
       " '184483889_2_0_0@4570064@1733167': [0, 4, 3, 2, 1],\n",
       " '189761997_0_0_3@7497218': [4, 2, 1, 0, 3],\n",
       " '189927896_2_0_1@9192723': [4, 3, 2, 1, 0],\n",
       " '195218693_1_0_2@59600034': [2, 3, 4, 0, 1],\n",
       " '195504787_0_0_1@21730715': [0, 1, 2, 3, 4],\n",
       " '196172757_1_0_2@3792324': [0, 1, 4, 3, 2],\n",
       " '196172757_2_0_7@53216389': [1, 4, 0, 3, 2],\n",
       " '196180835_0_0_1@3513372@15418780': [2, 3, 0, 1, 4],\n",
       " '196182403_1_0_1@67855531': [4, 0, 1, 3, 2],\n",
       " '196189186_1_0_4@1238927': [1, 0, 3, 2, 4],\n",
       " '196197006_3_0_0@52290656@29151507@59600051': [2, 4, 0, 3, 1],\n",
       " '196208296_0_0_1@16538528': [4, 2, 0, 3, 1],\n",
       " '197465409_0_0_1@7663461': [0, 3, 2, 1, 4],\n",
       " '198184826_3_0_1@20981275': [1, 4, 2, 0, 3],\n",
       " '198974416_0_0_4@19232497@51878571': [4, 2, 1, 3, 0],\n",
       " '199372933_2_0_0@2012188': [1, 3, 0, 4, 2],\n",
       " '199379475_2_0_0@49564245': [0, 1, 2, 3, 4],\n",
       " '201657196_0_0_6@15352384': [1, 3, 2, 4, 0],\n",
       " '201741377_0_0_0@6413281': [4, 0, 1, 2, 3],\n",
       " '202234053_1_0_0@29151507': [0, 2, 3, 1, 4],\n",
       " '202540640_0_0_0@9135033@2369967': [1, 2, 4, 3, 0],\n",
       " '202540793_2_0_7@1950452': [2, 4, 1, 0, 3],\n",
       " '202541185_1_0_0@53035038': [3, 4, 0, 1, 2],\n",
       " '202541632_0_0_2@3939596': [0, 3, 1, 2, 4],\n",
       " '202542397_0_0_1@1733167@1721388': [4, 1, 3, 2, 0],\n",
       " '202766392_0_0_5@19099243': [4, 2, 0, 1, 3],\n",
       " '202766615_2_0_0@14816251': [2, 0, 1, 3, 4],\n",
       " '202776138_0_0_7@102350939': [2, 4, 3, 0, 1],\n",
       " '207892291_2_0_0@15747255': [0, 2, 3, 1, 4],\n",
       " '208263110_0_0_0@54460803': [2, 3, 1, 4, 0],\n",
       " '209079290_0_0_1@3135458': [3, 0, 1, 4, 2],\n",
       " '209082217_1_0_2@67856005': [0, 3, 4, 2, 1],\n",
       " '209892309_0_0_7@5955929': [4, 1, 0, 3, 2],\n",
       " '57721315_3_0_1@52041587': [2, 0, 3, 4, 1],\n",
       " '59604441_0_0_4@5564363': [3, 0, 1, 4, 2],\n",
       " '67769427_0_0_1@5634542': [4, 2, 0, 1, 3],\n",
       " '67769427_1_0_0@5063437': [4, 2, 1, 0, 3],\n",
       " '67855635_1_0_2@748227@85501317': [1, 2, 4, 0, 3],\n",
       " '67856013_0_0_1@18563136': [1, 3, 2, 0, 4],\n",
       " '67856013_1_0_0@10289085': [3, 0, 2, 4, 1],\n",
       " '75134948_2_0_1@14838925': [0, 4, 1, 2, 3],\n",
       " '90242101_0_0_0@20272964': [4, 2, 3, 1, 0]}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "68e0ed48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 30.61it/s]\n"
     ]
    }
   ],
   "source": [
    "for ID, config_indices in tqdm(group_config.items()):\n",
    "    output = integrated_outputs[ID]\n",
    "    concat_preds = []\n",
    "    for k,v in output[\"predictions\"].items():\n",
    "        concat_preds.append(v)\n",
    "    citation_marks = output[\"citations\"]\n",
    "    pred = \" \".join(concat_preds)\n",
    "    highlights = set(remove_stop(word_tokenize(remove_citation_marks(pred, citation_marks))))\n",
    "    \n",
    "    retrieved_sentence_ids = set([])\n",
    "    for name in [\"context_ids\", \"oracle_ids\", \"keyword_ids\"]:\n",
    "        for idx in output[name]:\n",
    "            if idx >= 0:\n",
    "                retrieved_sentence_ids.add(idx)\n",
    "    retrieved_sentence_ids = sorted(list(retrieved_sentence_ids))\n",
    "    sentence_CTS = []\n",
    "    for si in retrieved_sentence_ids:\n",
    "        cited_text = sentence_cited_dataset[si][\"text\"]\n",
    "        author = sentence_cited_dataset[si][\"title\"]\n",
    "        highlighted_sentence = highlight_words(cited_text, highlights)\n",
    "        sentence_CTS.append(author + \" ## \" + highlighted_sentence)\n",
    "    output[\"sentence_CTS\"] = sentence_CTS\n",
    "    \n",
    "    retrieved_paragraph_ids = set([])\n",
    "    for idx in output[\"abstract_ids\"]:\n",
    "        if idx >= 0:\n",
    "            retrieved_paragraph_ids.add(idx)\n",
    "    retrieved_paragraph_ids = sorted(list(retrieved_paragraph_ids))\n",
    "    abstracts = []\n",
    "    for pi in retrieved_paragraph_ids:\n",
    "        cited_text = paragraph_cited_dataset[pi][\"text\"]\n",
    "        author = paragraph_cited_dataset[pi][\"title\"]\n",
    "        highlighted_abstract = highlight_words(cited_text, highlights)\n",
    "        abstracts.append(author + \" ## \" +highlighted_abstract)\n",
    "    output[\"abstracts\"] = abstracts\n",
    "\n",
    "    shuffle_order = \"\".join([str(i) for i in config_indices])\n",
    "    with open(base_dir + ID+\".html\",\"w\") as f:\n",
    "        f.write(\"Span ID: \"+ID+\"$\"+\"<br>\")\n",
    "        f.write(\"<h2>Context (Up to 2 sentences before the target citation):</h2>\")\n",
    "        f.write(output[\"context\"])\n",
    "        f.write(\"<h2>Randomized System Outputs:</h2>\")\n",
    "        for i, idx in enumerate(config_indices):\n",
    "            config = configs[idx]\n",
    "            f.write(str(i+1)+\". \"+config+\": \"+output[\"predictions\"][config]+\"<br>\")\n",
    "        f.write(\"<h2>Cited Abstracts:</h2>\")\n",
    "        for abstract in abstracts:\n",
    "            f.write(abstract)\n",
    "        f.write(\"<h2>Retrieved Body Sentences:</h2>\")\n",
    "        for cts in sentence_CTS:\n",
    "            f.write(cts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b46fa6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
