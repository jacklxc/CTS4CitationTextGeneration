{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8b965734",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import xml.etree.ElementTree as ET\n",
    "import math\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from rouge_score import rouge_scorer\n",
    "from sklearn.metrics import cohen_kappa_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a8b0f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sentence(text):\n",
    "    text = text.replace(\"&quot;\",'\"')\n",
    "    text = text.replace(\"-\",' ')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "095c3dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(sentence):\n",
    "    tokens = word_tokenize(sentence)\n",
    "    cleaned_tokens = []\n",
    "    for token in tokens:\n",
    "        if token not in stops:\n",
    "            cleaned_tokens.append(token)\n",
    "    return \" \".join(cleaned_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bcbc316",
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ed770b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = rouge_scorer.RougeScorer(['rouge1','rouge2'], use_stemmer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49db3264",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"/home/xxl190027/scisumm-corpus/data/Test-Set-2018/\"\n",
    "files = glob(base_dir+\"*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c94faf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_texts = {}\n",
    "for file in files:\n",
    "    paper_name = os.path.split(file)[-1]\n",
    "    xml_path = file + \"/Reference_XML/\"+paper_name+\".xml\"\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "    sentences = {}\n",
    "    for node in root.findall(\"S\"):\n",
    "        sentence = node.text.strip().replace(\"  \",\" \")\n",
    "        sentence = clean_sentence(sentence)\n",
    "        sid = int(node.attrib[\"sid\"])\n",
    "        sentences[sid] = {\n",
    "            \"text\": sentence,\n",
    "            \"no_stop\": remove_stop_words(sentence).lower(),\n",
    "        }\n",
    "    for abstract_node in root.findall(\"ABSTRACT\"):\n",
    "        for node in abstract_node.findall(\"S\"):\n",
    "            sentence = node.text.strip().replace(\"  \",\" \")\n",
    "            sentence = clean_sentence(sentence)\n",
    "            sid = int(node.attrib[\"sid\"])\n",
    "            sentences[sid] = {\n",
    "                \"text\": sentence,\n",
    "                \"no_stop\": remove_stop_words(sentence).lower(),\n",
    "            }\n",
    "    for section_node in root.findall(\"SECTION\"):\n",
    "        for node in section_node.findall(\"S\"):\n",
    "            sentence = node.text.strip().replace(\"  \",\" \")\n",
    "            sentence = clean_sentence(sentence)\n",
    "            sid = int(node.attrib[\"sid\"])\n",
    "            sentences[sid] = {\n",
    "                \"text\": sentence,\n",
    "                \"no_stop\": remove_stop_words(sentence).lower(),\n",
    "            }\n",
    "    full_texts[paper_name] = sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1828a103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "191"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full_texts['A00-2018'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a751bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir_gold = \"/home/xxl190027/scisumm-corpus/data/Test-Set-2018-Gold/Task1/\"\n",
    "gold_files = glob(base_dir_gold+\"*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bd5ff739",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_annotations = {}\n",
    "annotators = set([])\n",
    "for gold_file in gold_files:\n",
    "    gold_file_name = os.path.split(gold_file)[-1]\n",
    "    paper_name, annotator = gold_file_name.split(\".\")[0].split(\"_\")\n",
    "    annotators.add(annotator)\n",
    "    df = pd.read_csv(gold_file)\n",
    "    this_paper = all_annotations.get(paper_name, {})\n",
    "    for i in range(len(df)):\n",
    "        this_citance = this_paper.get(df[\"Citance Number\"][i], {\n",
    "            \"Citing Article\": df[\"Citing Article\"][i],\n",
    "            \"Citation Text\": df[\"Citation Text Clean\"][i],\n",
    "            \"CTS\": {},\n",
    "        })\n",
    "        \n",
    "        #print(this_citance[\"Citation Text\"] , df[\"Citation Text Clean\"][i])\n",
    "        if this_citance[\"Citing Article\"] != df[\"Citing Article\"][i]:\n",
    "            continue\n",
    "            #print(paper_name, annotator, df[\"Citance Number\"][i], this_citance[\"Citing Article\"] , df[\"Citing Article\"][i])\n",
    "        #assert(this_citance[\"Citing Article\"] == df[\"Citing Article\"][i])\n",
    "        #assert(this_citance[\"Citation Text\"] == df[\"Citation Text Clean\"][i])\n",
    "        raw_offsets = df[\"Reference Offset\"][i]\n",
    "        offsets = []\n",
    "        if type(raw_offsets)==str and raw_offsets not in {\"0\",\"???\"}:\n",
    "            raw_offsets = raw_offsets.replace(\";\",\",\")\n",
    "            for num_str in raw_offsets.split(\",\"):\n",
    "                cleaned = num_str.strip().replace(\"'\",\"\")\n",
    "                if cleaned:\n",
    "                    offsets.append(int(cleaned))\n",
    "        elif type(raw_offsets) == np.float64 and not np.isnan(raw_offsets):\n",
    "            offsets.append(int(raw_offsets))\n",
    "        elif type(raw_offsets) == np.int64:\n",
    "            offsets.append(int(raw_offsets))\n",
    "        this_citance[\"CTS\"][annotator] = offsets\n",
    "        this_paper[df[\"Citance Number\"][i]] = this_citance\n",
    "    all_annotations[paper_name] = this_paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1832cb6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A00-2018': {2: {'Citing Article': 'N10-1002',\n",
       "   'Citation Text': 'As a benchmark VPC extraction system, we use the Charniak parser (Charniak, 2000)',\n",
       "   'CTS': {'akanksha': [90, 91], 'sweta': [17], 'vardha': [5]}},\n",
       "  3: {'Citing Article': 'W11-0610',\n",
       "   'Citation Text': 'Each of these scores can be calculated from a provided syntactic parse tree, and to generate these we made use of the Charniak parser (Charniak, 2000), also trained on the Switch board tree bank',\n",
       "   'CTS': {'akanksha': [5], 'sweta': [5], 'vardha': [5]}},\n",
       "  4: {'Citing Article': 'W06-3119',\n",
       "   'Citation Text': \"We then use Charniak's parser (Charniak, 2000) to generate the most likely parse tree for each English target sentence in the training corpus\",\n",
       "   'CTS': {'akanksha': [90], 'sweta': [17], 'vardha': [91]}},\n",
       "  5: {'Citing Article': 'N03-2024',\n",
       "   'Citation Text': \"We were interested in the occurrence of features such as type and number of premodifiers, presence and type of post modifiers, and form of name reference for people. We constructed a large, automatically annotated corpus by merging the output of Charniak's statistical parser (Charniak, 2000) with that of the IBM named entity recognition system Nominator (Wacholder et al,1997)\",\n",
       "   'CTS': {'akanksha': [48, 49, 51], 'sweta': [120], 'vardha': [39]}},\n",
       "  6: {'Citing Article': 'N06-1039',\n",
       "   'Citation Text': 'After getting a set of basic clusters, we pass them to an existing statistical parser (Charniak, 2000) and rule-based tree normalizer to obtain a GLARF structure for each sentence in every article',\n",
       "   'CTS': {'akanksha': [90, 91, 92, 93, 94], 'sweta': [119], 'vardha': []}},\n",
       "  7: {'Citing Article': 'C04-1180',\n",
       "   'Citation Text': 'The levels of accuracy and robustness recently achieved by statistical parsers (e.g. Collins (1999), Charniak (2000)) have led to their use in a number of NLP applications, such as question-answering (Pasca and Harabagiu, 2001), machine translation (Charniak et al, 2003), sentence simplification (Carroll et al, 1999), and a linguist? s search engine (Resnik and Elkiss, 2003)',\n",
       "   'CTS': {'akanksha': [], 'sweta': [95], 'vardha': [162]}},\n",
       "  8: {'Citing Article': 'W05-0638',\n",
       "   'Citation Text': 'In CoNLL-2005, full parsing trees are provided by two full parsers: the Collins parser (Collins, 1999) and the Charniak parser (Charniak, 2000)',\n",
       "   'CTS': {'akanksha': [90], 'sweta': [175], 'vardha': [87]}},\n",
       "  9: {'Citing Article': 'P05-1065',\n",
       "   'Citation Text': 'We also use a standard statistical parser (Charniak, 2000) to provide syntactic analysis',\n",
       "   'CTS': {'akanksha': [90, 91, 92, 93, 94], 'sweta': [92], 'vardha': [91]}},\n",
       "  10: {'Citing Article': 'P05-1065',\n",
       "   'Citation Text': 'For each article, we calculated the percentage of a) all word instances (tokens) and b) all unique words (types) not on these lists, resulting in three token OOV rate features and three type OOV rate features per article. The parse features are generated using the Charniak parser (Charniak, 2000) trained on the standard Wall Street Journal Treebank corpus',\n",
       "   'CTS': {'akanksha': [38, 39, 40], 'sweta': [1], 'vardha': [176]}},\n",
       "  11: {'Citing Article': 'P04-1040',\n",
       "   'Citation Text': 'The evaluation of the transformed output of the parsers of Charniak (2000) and Collins (1999) gives 90 % unlabelled and 84 % labelled accuracy with respect to dependencies, when measured against a dependency corpus derived from the Penn Treebank. The paper is organized as follows',\n",
       "   'CTS': {'akanksha': [174], 'sweta': [126], 'vardha': [174]}},\n",
       "  13: {'Citing Article': 'P04-1040',\n",
       "   'Citation Text': 'As an alternative to hard coded heuristics, Blaheta and Charniak (2000) proposed to recover the Penn functional tags automatically',\n",
       "   'CTS': {'akanksha': [85], 'sweta': [174], 'vardha': [155]}},\n",
       "  17: {'Citing Article': 'N06-1022',\n",
       "   'Citation Text': 'The parser of Charniak (2000) is also a two-stage ctf model, where the first stage is a smoothed Markov grammar (it uses up to three previous constituents as context), and the second stage is a lexicalized Markov grammar with extra annotations about parents and grandparents',\n",
       "   'CTS': {'akanksha': [63, 143, 146], 'sweta': [63], 'vardha': [40]}},\n",
       "  18: {'Citing Article': 'N06-1022',\n",
       "   'Citation Text': 'Most recently, McDonald et al (2005) have implemented a dependency parser with good accuracy (it is almost as good at dependency parsing as Charniak (2000)) and very impressive speed (it is about ten times faster than Collins (1997) and four times faster than Charniak (2000))',\n",
       "   'CTS': {'akanksha': [78, 79], 'sweta': [78], 'vardha': [79]}},\n",
       "  19: {'Citing Article': 'H05-1035',\n",
       "   'Citation Text': 'The feature set contains complex information extracted automatically from candidate syntax trees generated by parsing (Charniak, 2000), trees that will be improved by more accurate PP-attachment decisions',\n",
       "   'CTS': {'akanksha': [90], 'sweta': [91], 'vardha': [40]}},\n",
       "  20: {'Citing Article': 'P04-1042',\n",
       "   'Citation Text': \"Note that the dependency figures of Dienes lag behind even the parsed results for Johnson's model; this may well be due to the fact that Dienes built his model as an extension of Collins (1999), which lags behind Charniak (2000) by about 1.3-1.5%. Manual investigation of errors on English gold standard data revealed two major issues that suggest further potential for improvement in performance without further increase in algorithmic complexity or training set size\",\n",
       "   'CTS': {'akanksha': [174], 'sweta': [180], 'vardha': [175]}},\n",
       "  12: {'Citing Article': 'P04-1040',\n",
       "   'Citation Text': 'Blaheta and Charniak (2000) presented the first method for assigning Penn functional tags to constituents identified by a parser. Pattern-matching approaches were used in (Johnson, 2002) and (Jijkoun, 2003) to recover non-local dependencies in phrase trees',\n",
       "   'CTS': {'sweta': [12], 'vardha': [101]}},\n",
       "  14: {'Citing Article': 'P04-1040',\n",
       "   'Citation Text': 'Thus, it is informative to compare our results with those reported in (Blaheta and Charniak, 2000) for this same task',\n",
       "   'CTS': {'vardha': [17]}},\n",
       "  15: {'Citing Article': 'P04-1040',\n",
       "   'Citation Text': \"Method Accuracy P R f Blaheta 98.6 87.2 87.4 87.3 This paper 94.7 90.2 86.9 88.5 The difference in the accuracy is due to two reasons. First, because of the different definition of a correctly identified constituent in the parser's output, we apply our method to a greater portion of all labels produced by the parser (95% vs. 89% reported in (Blaheta and Charniak, 2000))\",\n",
       "   'CTS': {'vardha': [162]}}},\n",
       " 'A00-2030': {1: {'Citing Article': 'W01-0510',\n",
       "   'Citation Text': 'Section 5 compares our approach too thiers in the literature, in particular that of (Miller et al., 2000)',\n",
       "   'CTS': {'aakansha': [4], 'sweta': [18], 'vardha': [11]}},\n",
       "  2: {'Citing Article': 'W01-0510',\n",
       "   'Citation Text': 'The basic approach we described is very similar to the one presented in (Miller et al, 2000) however there are a few major differences: \\x0f in our approach the augmentation of the syn tactic tags with semantic tags is straightforward due to the fact that the semantic constituents are matched exactly 5. The approach in (Miller',\n",
       "   'CTS': {'aakansha': [33, 34], 'sweta': [100], 'vardha': [52]}},\n",
       "  3: {'Citing Article': 'W01-0510',\n",
       "   'Citation Text': 'The semantic annotation required by our task is much simpler than that employed by (Miller et al, 2000)',\n",
       "   'CTS': {'aakansha': [49, 50], 'sweta': [52], 'vardha': [50]}},\n",
       "  4: {'Citing Article': 'W01-0510',\n",
       "   'Citation Text': 'One possibly beneficial extension of our work suggested by (Miller et al, 2000) would be to add semantic tags describing relations between entities (slots), in which case the semantic constraints would not be structured strictly on the two levels used in the current approach, respectively frame and slot level',\n",
       "   'CTS': {'aakansha': [33, 34], 'sweta': [34], 'vardha': [34]}},\n",
       "  5: {'Citing Article': 'W01-0510',\n",
       "   'Citation Text': 'Similar to the approach in (Miller et al, 2000) we initialized the SLM statistics from the UPenn Tree bank parse trees',\n",
       "   'CTS': {'aakansha': [10], 'sweta': [1], 'vardha': [106]}},\n",
       "  6: {'Citing Article': 'P14-1078',\n",
       "   'Citation Text': 'Rule-based methods (Miller et al, 2000) employ a number of linguistic rules to capture relation patterns',\n",
       "   'CTS': {'aakansha': [16], 'sweta': [61], 'vardha': [6]}},\n",
       "  7: {'Citing Article': 'P05-1061',\n",
       "   'Citation Text': 'One interesting system that does not belong to the above class is that of Miller et al (2000), who take the view that relation extraction is just a form of probabilistic parsing where parse trees are augmented to identify all relations',\n",
       "   'CTS': {'aakansha': [33, 34], 'sweta': [104], 'vardha': [6]}},\n",
       "  8: {'Citing Article': 'P05-1053',\n",
       "   'Citation Text': 'Miller et al (2000) augmented syntactic full parse trees with semantic information corresponding to entities and relations, and built generative models for the augmented trees',\n",
       "   'CTS': {'aakansha': [33, 34], 'sweta': [32], 'vardha': [34]}},\n",
       "  9: {'Citing Article': 'P05-1053',\n",
       "   'Citation Text': 'Complicated relation extraction tasks may also impose a big challenge to the modeling approach used by Miller et al (2000) which integrates various tasks such as part-of-speech tagging, named entity recognition, template element extraction and relation extraction, in a single model',\n",
       "   'CTS': {'aakansha': [23, 24], 'sweta': [2], 'vardha': [12]}},\n",
       "  10: {'Citing Article': 'H05-1094',\n",
       "   'Citation Text': '(Miller et al, 2000) have combined entity recognition, parsing, and relation extraction into a jointly-trained single statistical parsing model that achieves improved performance on all the subtasks. Part of the contribution of the current work is to suggest that joint decoding can be effective even when joint training is not possible because jointly-labeled data is unavailable',\n",
       "   'CTS': {'aakansha': [23, 24], 'sweta': [61], 'vardha': [3]}},\n",
       "  11: {'Citing Article': 'P04-1054',\n",
       "   'Citation Text': 'Miller et al (2000) propose an integrated statistical parsing technique that augments parse trees with semantic labels denoting entity and relation types',\n",
       "   'CTS': {'aakansha': [23, 24, 33, 34], 'sweta': [33], 'vardha': [34]}},\n",
       "  12: {'Citing Article': 'P04-1054',\n",
       "   'Citation Text': 'Whereas Miller et al (2000) use a generative model to produce parse information as well as relation information, we hypothesize that a technique discriminatively trained to classify relations will achieve better performance',\n",
       "   'CTS': {'aakansha': [33, 34], 'sweta': [34], 'vardha': [32]}},\n",
       "  13: {'Citing Article': 'W05-0602',\n",
       "   'Citation Text': \"The syntactic model in (Miller et al, 2000) is similar to Collins', but does not use features like subcat frames and distance measures\",\n",
       "   'CTS': {'aakansha': [60, 61], 'sweta': [3], 'vardha': [10]}},\n",
       "  14: {'Citing Article': 'N07-2041',\n",
       "   'Citation Text': 'Similar to the approach in (Miller et al, 2000) and (Kulick et al, 2004), our parser integrates both syntactic and semantic annotations into a single annotation as shown in Figure 2',\n",
       "   'CTS': {'aakansha': [33], 'sweta': [52], 'vardha': [94]}},\n",
       "  15: {'Citing Article': 'W10-2924',\n",
       "   'Citation Text': 'Miller et al (2000) adapt a probabilistic context-free parser for information extraction by augmenting syntactic labels with entity and relation labels',\n",
       "   'CTS': {'aakansha': [33, 34], 'sweta': [104], 'vardha': [6]}},\n",
       "  16: {'Citing Article': 'W06-0508',\n",
       "   'Citation Text': 'Most of the approaches for relation extraction rely on the mapping of syntactic dependencies, such as SVO, onto semantic relations, using either pattern matching or other strategies, such as probabilistic parsing for trees augmented with annotations for entities and relations (Miller et al 2000), or clustering of semantically similar syntactic dependencies, according to their selectional restrictions (Gamallo et al, 2002)',\n",
       "   'CTS': {'aakansha': [33, 34], 'sweta': [104], 'vardha': [104]}},\n",
       "  17: {'Citing Article': 'P07-1055',\n",
       "   'Citation Text': 'This includes parsing and relation extraction (Miller et al, 2000), entity labeling and relation extraction (Roth and Yih, 2004), and part-of-speech tagging and chunking (Sutton et al, 2004)',\n",
       "   'CTS': {'aakansha': [11, 12, 16], 'sweta': [2], 'vardha': [26]}},\n",
       "  18: {'Citing Article': 'W05-0636',\n",
       "   'Citation Text': 'For example, Miller et al (2000) showed that performing parsing and information extraction in a joint model improves performance on both tasks',\n",
       "   'CTS': {'aakansha': [105], 'sweta': [104], 'vardha': [6]}},\n",
       "  19: {'Citing Article': 'N06-1037',\n",
       "   'Citation Text': 'Miller et al (2000) address the task of relation extraction from the statistical parsing viewpoint',\n",
       "   'CTS': {'aakansha': [60, 61], 'sweta': [2], 'vardha': [19]}},\n",
       "  20: {'Citing Article': 'D11-1132',\n",
       "   'Citation Text': 'Rule-based methods (Miller et al, 2000) employ a number of linguistic rules to capture relation patterns',\n",
       "   'CTS': {'aakansha': [16], 'sweta': [61], 'vardha': []}}},\n",
       " 'A97-1014': {1: {'Citing Article': 'E99-1016',\n",
       "   'Citation Text': 'This type of model is used to facilitate the syntactic annotation of the NEGRA corpus of German newspaper texts (Skut et al, 1997)',\n",
       "   'CTS': {'swastika': [168], 'sweta': [168], 'vardha': [72]}},\n",
       "  2: {'Citing Article': 'E99-1016',\n",
       "   'Citation Text': 'For our experiments, we use the NEGRA corpus (Skut et al, 1997)',\n",
       "   'CTS': {'swastika': [168], 'sweta': [165], 'vardha': [144]}},\n",
       "  3: {'Citing Article': 'E12-1047',\n",
       "   'Citation Text': 'As data we use version 2 of the Negra (Skut et al1997) tree bank, with the common training',\n",
       "   'CTS': {'swastika': [151], 'sweta': [145], 'vardha': [14]}},\n",
       "  5: {'Citing Article': 'I05-6010',\n",
       "   'Citation Text': 'According to Skut et al (1997) tree banks have to meet the following requirements: 1',\n",
       "   'CTS': {'swastika': [15], 'sweta': [15], 'vardha': [15]}},\n",
       "  7: {'Citing Article': 'C10-1061',\n",
       "   'Citation Text': 'In contrast, some other tree banks, such as the German NeGra and TIGER tree banks allow annotation with crossing branches (Skut et al, 1997). Non-local dependencies can then be expressed directly by grouping all dependent elements under a single node',\n",
       "   'CTS': {'swastika': [47], 'sweta': [47], 'vardha': [24]}},\n",
       "  8: {'Citing Article': 'C10-1061',\n",
       "   'Citation Text': 'Our data source is the German NeGra tree bank (Skut et al, 1997)',\n",
       "   'CTS': {'swastika': [167], 'sweta': [167], 'vardha': [160]}},\n",
       "  9: {'Citing Article': 'P05-1039',\n",
       "   'Citation Text': 'The parsing models we present are trained and tested on the NEGRA corpus (Skut et al, 1997), a hand parsed corpus of German newspaper text containing approximately 20,000 sentences',\n",
       "   'CTS': {'swastika': [168], 'sweta': [167], 'vardha': [151]}},\n",
       "  10: {'Citing Article': 'P03-1013',\n",
       "   'Citation Text': 'The present paper addresses this question by proposing a probabilistic parsing model trained on Negra (Skut et al, 1997), a syntactically annotated corpus for German',\n",
       "   'CTS': {'swastika': [4], 'sweta': [39], 'vardha': [4]}},\n",
       "  11: {'Citing Article': 'P03-1013',\n",
       "   'Citation Text': 'The annotation scheme (Skut et al, 1997) is modeled to a certain extent on that of the Penn Treebank (Marcuset al, 1993), with crucial differences',\n",
       "   'CTS': {'swastika': [160], 'sweta': [160], 'vardha': [160]}},\n",
       "  13: {'Citing Article': 'W04-1505',\n",
       "   'Citation Text': 'German is considerably more in ectional which means that discarding functional information is more harmful, and which explains why the NEGRA annotation has been conceived to be quite at (Skut et al, 1997)',\n",
       "   'CTS': {'swastika': [127], 'sweta': [166], 'vardha': [167]}},\n",
       "  14: {'Citing Article': 'C04-1074',\n",
       "   'Citation Text': 'The factors used in the algorithms and the algorithms themselves are evaluated on a German corpus annotated with syntactic and co reference in formation (Negra) (Skut et al, 1997)',\n",
       "   'CTS': {'swastika': [39], 'sweta': [166], 'vardha': [39]}},\n",
       "  16: {'Citing Article': 'P11-2067',\n",
       "   'Citation Text': 'CKK uses the Dubey and Keller (2003) parser, which is trained on the Negra corpus (Skut et al, 1997)',\n",
       "   'CTS': {'swastika': [72], 'sweta': [143], 'vardha': [151]}},\n",
       "  17: {'Citing Article': 'W08-1007',\n",
       "   'Citation Text': \"Earlier studies by Dubey and Keller (2003) and Dubey (2005) using the Negra treebank (Skut et al, 1997) reports that lexicalization of PCFGs decrease the parsing accuracy when parsing Negra's flat constituent structures\",\n",
       "   'CTS': {'swastika': [4], 'sweta': [71], 'vardha': [71]}},\n",
       "  19: {'Citing Article': 'D07-1066',\n",
       "   'Citation Text': 'A comparison of unlexicalised PCFG parsing (Kubler, 2005) trained and evaluated on the German NEGRA (Skut et al, 1997) and the Tu? Ba D/Z (Telljohann et al, 2004) tree banks using LoPar (Schmid, 2000) shows a difference in parsing results of about 16%, using the PARSEVAL metric (Black et al, 1991)',\n",
       "   'CTS': {'swastika': [4], 'sweta': [151], 'vardha': [160]}},\n",
       "  6: {'Citing Article': 'W04-1506',\n",
       "   'Citation Text': 'that could best deal with the free word order displayed by Basque syntax (Skut et al, 1997)',\n",
       "   'CTS': {'sweta': [41], 'vardha': [36]}},\n",
       "  18: {'Citing Article': 'P06-1109',\n",
       "   'Citation Text': 'We next tested UML-DOP on two additional domains which were also used in Klein and Manning (2004) and Bod (2006): the German NEGRA 10 (Skut et al 1997) and the Chinese CTB10 (Xue et al 2002) both containing 2200+ sentences 10 words after removing punctuation',\n",
       "   'CTS': {'sweta': [167], 'vardha': [144]}}},\n",
       " 'D09-1092': {1: {'Citing Article': 'P14-1004',\n",
       "   'Citation Text': 'This configuration is similar to PolyLDA (Mimno et al, 2009) or LinkLDA (Yano et al, 2009), such that utterances from different parties are treated as different languages or blog-post and comments pairs',\n",
       "   'CTS': {'swastika': [193], 'sweta': [32], 'vardha': [17]}},\n",
       "  2: {'Citing Article': 'P10-1044',\n",
       "   'Citation Text': 'Our particular model, LinkLDA, has been applied to a few NLP tasks such as simultaneously modeling the words appearing in blog posts and users who will likely respond to them (Yano et al, 2009), modeling topic-aligned articles in different languages (Mimno et al, 2009), and word sense induction (Brody and Lapata, 2009)',\n",
       "   'CTS': {'swastika': [114], 'sweta': [39], 'vardha': [20]}},\n",
       "  3: {'Citing Article': 'P11-2084',\n",
       "   'Citation Text': '(Mimno et al, 2009) retrieve a list of potential translations simply by selecting a small number N of the most probable words in both languages and then add the Cartesian product of these sets for every topic to a set of candidate translations',\n",
       "   'CTS': {'swastika': [138], 'sweta': [138], 'vardha': [138]}},\n",
       "  4: {'Citing Article': 'E12-1014',\n",
       "   'Citation Text': 'Our Wikipedia-based topic similarity feature, w (f, e), is similar in spirit to polylingual topic models (Mimno et al 2009), but it is scalable to full bilingual lexicon induction',\n",
       "   'CTS': {'swastika': [18], 'sweta': [196], 'vardha': [10]}},\n",
       "  5: {'Citing Article': 'D11-1086',\n",
       "   'Citation Text': 'For Europarl data sets, we artificially make them comparable by considering the first half of English document and the second half of its aligned foreign language document (Mimno et al,2009)',\n",
       "   'CTS': {'swastika': [55], 'sweta': [111], 'vardha': [55]}},\n",
       "  6: {'Citing Article': 'N12-1007',\n",
       "   'Citation Text': 'Since the PLTM is not a contribution of this paper, we refer the interested reader to (Mimno et al, 2009) for more details',\n",
       "   'CTS': {'swastika': [192], 'sweta': [128], 'vardha': [9]}},\n",
       "  7: {'Citing Article': 'N12-1007',\n",
       "   'Citation Text': 'Mimno et al (2009) showed that so long as the proportion of topically-aligned to non-aligned documents exceeded 0.25, the topic distributions (as measured by mean Jensen-Shannon Divergence between distributions) did not degrade significantly',\n",
       "   'CTS': {'swastika': [119], 'sweta': [122], 'vardha': [118]}},\n",
       "  8: {'Citing Article': 'D10-1025',\n",
       "   'Citation Text': 'Similarly, Polylingual Topic Models (PLTM) (Mimno et al, 2009) generalized LDA to tuples of documents from multiple languages',\n",
       "   'CTS': {'swastika': [148], 'sweta': [35], 'vardha': [35]}},\n",
       "  9: {'Citing Article': 'D10-1025',\n",
       "   'Citation Text': 'Our baseline joint PLSA model (JPLSA) is closely related to the poly-lingual LDA model of (Mimno et al, 2009)',\n",
       "   'CTS': {'swastika': [193], 'sweta': [110], 'vardha': [35]}},\n",
       "  10: {'Citing Article': 'D10-1025',\n",
       "   'Citation Text': 'We describe the model for two languages, but it is straightforward to generalize to more than two languages, as in (Mimno et al, 2009)',\n",
       "   'CTS': {'swastika': [184], 'sweta': [30], 'vardha': [55]}},\n",
       "  11: {'Citing Article': 'D10-1025',\n",
       "   'Citation Text': 'The difference between the JPLSA model and the poly-lingual topic model of (Mimno et al, 2009) is that we merge the vocabularies in the two languages and learn topic-specific word distributions over these merged vocabularies, instead of having pairs of topic-specific word distributions, one for each language, like in (Mimno et al, 2009)',\n",
       "   'CTS': {'swastika': [193], 'sweta': [146], 'vardha': [102]}},\n",
       "  12: {'Citing Article': 'D10-1025',\n",
       "   'Citation Text': 'Another difference between our model and the poly-lingual LDA model of (Mimno et al, 2009) is that we use maximum aposteriori (MAP) instead of Bayesian inference',\n",
       "   'CTS': {'swastika': [163], 'sweta': [77], 'vardha': [38]}},\n",
       "  13: {'Citing Article': 'D10-1025',\n",
       "   'Citation Text': 'For computing distance we used the L1-norm of the difference, which worked a bit better than the Jensen Shannon divergence between the topic vectors used in (Mimno et al, 2009)',\n",
       "   'CTS': {'swastika': [184], 'sweta': [156], 'vardha': [156]}},\n",
       "  15: {'Citing Article': 'D10-1025',\n",
       "   'Citation Text': 'In previously reported work, (Mimno et al, 2009) evaluate parallel document retrieval using PLTM on Europarl speeches in English and Spanish, using training and test sets of size similar to ours',\n",
       "   'CTS': {'swastika': [148], 'sweta': [19], 'vardha': [170]}},\n",
       "  16: {'Citing Article': 'W12-3117',\n",
       "   'Citation Text': 'Multilingual LDA has been used before in natural language processing, e.g. polylingual topic models (Mimno et al, 2009) or multilingual topic models for unaligned text (Boyd-Graber and Blei, 2009)',\n",
       "   'CTS': {'swastika': [184], 'sweta': [131], 'vardha': [29]}},\n",
       "  17: {'Citing Article': 'W11-2133',\n",
       "   'Citation Text': 'Mimno et al (2009) extend the original concept of LDA to support polylingual topic models (PLTM), both on parallel (such as EuroParl) and partly comparable documents (such as Wikipedia articles)',\n",
       "   'CTS': {'swastika': [193], 'sweta': [196], 'vardha': [170]}},\n",
       "  18: {'Citing Article': 'W11-2133',\n",
       "   'Citation Text': 'Mimno et al (2009) show that PLTM sufficiently aligns topics in parallel corpora',\n",
       "   'CTS': {'swastika': [192], 'sweta': [192], 'vardha': [168]}},\n",
       "  19: {'Citing Article': 'P14-2110',\n",
       "   'Citation Text': 'A good candidate for multilingual topic analyses are polylingual topic models (Mimno et al, 2009), which learn topics for multiple languages, creating tuples of language specific distributions over monolingual vocabularies for each topic',\n",
       "   'CTS': {'swastika': [105], 'sweta': [195], 'vardha': [29]}},\n",
       "  20: {'Citing Article': 'P14-2110',\n",
       "   'Citation Text': 'To train a polylingual topic model on social media, we make two modifications to the model of Mimno et al (2009): add a token specific language variable, and a process for identifying aligned top ics',\n",
       "   'CTS': {'swastika': [10], 'sweta': [6], 'vardha': [110]}},\n",
       "  14: {'Citing Article': 'D10-1025',\n",
       "   'Citation Text': 'Documents are defined as speeches by a single speaker, as in (Mimno et al, 2009)',\n",
       "   'CTS': {'sweta': [31], 'vardha': [36]}}},\n",
       " 'D10-1044': {1: {'Citing Article': 'P11-2074',\n",
       "   'Citation Text': 'Another popular task in SMT is domain adaptation (Foster et al, 2010)',\n",
       "   'CTS': {'aakansha': [144], 'swastika': [9], 'sweta': [4]}},\n",
       "  2: {'Citing Article': 'P12-1048',\n",
       "   'Citation Text': 'In addition, discriminative weighting methods were proposed to assign appropriate weights to the sentences from training corpus (Matsoukas et al, 2009) or the phrase pairs of phrase table (Foster et al, 2010)',\n",
       "   'CTS': {'aakansha': [95, 96], 'swastika': [], 'sweta': [132]}},\n",
       "  3: {'Citing Article': 'D12-1129',\n",
       "   'Citation Text': 'Domain knowledge also has the potential to improve open-text applications such as summarization (Ceylan et al 2010) and machine translation (Foster et al., 2010)',\n",
       "   'CTS': {'aakansha': [9], 'swastika': [9], 'sweta': [7]}},\n",
       "  4: {'Citing Article': 'P14-2093',\n",
       "   'Citation Text': 'Yasuda et al (2008) and Foster et al (2010) ranked the sentence pairs in the general-domain corpus according to the perplexity scores of sentences, which are computed with respect to in-domain language models',\n",
       "   'CTS': {'aakansha': [62], 'swastika': [62], 'sweta': [62]}},\n",
       "  5: {'Citing Article': 'E12-1055',\n",
       "   'Citation Text': 'Our main technical contributions are as follows: Additionally to perplexity optimization for linear interpolation, which was first applied by Foster et al (2010), we propose perplexity optimization for weighted counts (equation 3), and a modified implementation of linear interpolation',\n",
       "   'CTS': {'aakansha': [28], 'swastika': [71], 'sweta': [50]}},\n",
       "  6: {'Citing Article': 'E12-1055',\n",
       "   'Citation Text': 'Matsoukas et al (2009) propose an approach where each sentence is weighted according to a classifier, and Foster et al (2010) extend this approach by weighting individual phrase pairs',\n",
       "   'CTS': {'aakansha': [23], 'swastika': [96], 'sweta': [152]}},\n",
       "  7: {'Citing Article': 'E12-1055',\n",
       "   'Citation Text': 'Foster et al (2010) combine the two, applying linear interpolation to combine the instance weighted out-of-domain model with an in-domain model',\n",
       "   'CTS': {'aakansha': [144], 'swastika': [71], 'sweta': [144]}},\n",
       "  8: {'Citing Article': 'E12-1055',\n",
       "   'Citation Text': 'Note that both data sets have a relatively high ratio of in-domain to out-of-domain parallel training data (1:20 for DE? EN and 1:5 for HT? EN); Previous research has been performed with ratios of 1:100 (Foster et al 2010) or 1:400 (Axelrod et al 2011)',\n",
       "   'CTS': {'aakansha': [], 'swastika': [144], 'sweta': [9]}},\n",
       "  9: {'Citing Article': 'E12-1055',\n",
       "   'Citation Text': 'We expand on work by (Foster et al 2010) in establishing translation model perplexity minimization as a robust baseline for a weighted combination of translation models',\n",
       "   'CTS': {'aakansha': [9], 'swastika': [62], 'sweta': [75]}},\n",
       "  10: {'Citing Article': 'P12-1099',\n",
       "   'Citation Text': 'In addition to the basic approach of concatenation of in-domain and out-of-domain data, we also trained a log-linear mixture model (Foster and Kuhn, 2007) as well as the linear mixture model of (Foster et al, 2010) for conditional phrase-pair probabilities over IN and OUT',\n",
       "   'CTS': {'aakansha': [28], 'swastika': [45], 'sweta': [28]}},\n",
       "  11: {'Citing Article': 'P12-1099',\n",
       "   'Citation Text': 'Our technique for setting ? m is similar to that outlined in Foster et al (2010)',\n",
       "   'CTS': {'aakansha': [], 'swastika': [], 'sweta': [97]}},\n",
       "  12: {'Citing Article': 'P12-1099',\n",
       "   'Citation Text': 'For efficiency and stability, we use the EM algorithm to find ?, rather than L-BFGS as in (Foster et al., 2010)',\n",
       "   'CTS': {'aakansha': [75], 'swastika': [75], 'sweta': [75]}},\n",
       "  13: {'Citing Article': 'P12-1099',\n",
       "   'Citation Text': 'Foster et al (2010), however, uses a different approach to select related sentences from OUT',\n",
       "   'CTS': {'aakansha': [31], 'swastika': [], 'sweta': [143]}},\n",
       "  14: {'Citing Article': 'P12-1099',\n",
       "   'Citation Text': 'Foster et al (2010) propose a similar method for machine translation that uses features to capture degrees of generality',\n",
       "   'CTS': {'aakansha': [22], 'swastika': [22], 'sweta': [153]}},\n",
       "  15: {'Citing Article': 'P13-1126',\n",
       "   'Citation Text': 'As in (Foster et al, 2010), this approach works at the level of phrase pairs',\n",
       "   'CTS': {'aakansha': [23], 'swastika': [96], 'sweta': [144]}},\n",
       "  16: {'Citing Article': 'D11-1033',\n",
       "   'Citation Text': 'The ranking of the sentences in a general-domain corpus according to in-domain perplexity has also been applied to machine translation by both Yasuda et al (2008), and Foster et al (2010)',\n",
       "   'CTS': {'aakansha': [62], 'swastika': [62], 'sweta': [62]}},\n",
       "  17: {'Citing Article': 'D11-1033',\n",
       "   'Citation Text': 'Foster et al (2010) do not mention what percentage of the corpus they select for their IR-baseline, but they concatenate the data to their in-domain corpus and report a decrease in performance',\n",
       "   'CTS': {'aakansha': [119, 120], 'swastika': [42], 'sweta': [141]}},\n",
       "  18: {'Citing Article': 'D11-1033',\n",
       "   'Citation Text': 'Foster et al (2010) further perform this on extracted phrase pairs, not just sentences',\n",
       "   'CTS': {'aakansha': [23, 24], 'swastika': [96], 'sweta': [28]}},\n",
       "  19: {'Citing Article': 'P14-1012',\n",
       "   'Citation Text': 'To address the first shortcoming, we adapt and extend some simple but effective phrase features as the input features for new DNN feature learning, and these features have been shown significant improvement for SMT, such as, phrase pair similarity (Zhao et al, 2004), phrase frequency, phrase length (Hopkins and May, 2011), and phrase generative probability (Foster et al, 2010), which also show further improvement for new phrase feature learning in our experiments',\n",
       "   'CTS': {'aakansha': [40], 'swastika': [], 'sweta': [37]}}},\n",
       " 'E03-1005': {2: {'Citing Article': 'N06-1045',\n",
       "   'Citation Text': \"Data-Oriented Parsing (DOP)'s methodology is to calculate weighted derivations, but as noted in (Bod, 2003), it is the highest ranking parse, not derivation, that is desired\",\n",
       "   'CTS': {'aakansha': [105], 'swastika': [105], 'sweta': [20]}},\n",
       "  3: {'Citing Article': 'D07-1058',\n",
       "   'Citation Text': \"Goodman's transform, in combination with a range of heuristics, allowed Bod (2003) to run the DOP model on the Penn Treebank WSJ benchmark and obtain some of the best results obtained with a generative model\",\n",
       "   'CTS': {'aakansha': [145], 'swastika': [41], 'sweta': [74]}},\n",
       "  4: {'Citing Article': 'D07-1058',\n",
       "   'Citation Text': 'Zuidema (2006a) shows that also the estimator (Bod, 2003) uses is biased and inconsistent, and will, even in the limit of infinite data, not correctly identify many possible distributions over trees',\n",
       "   'CTS': {'aakansha': [80], 'swastika': [80], 'sweta': [44]}},\n",
       "  5: {'Citing Article': 'P11-1086',\n",
       "   'Citation Text': 'Second, we compare against a composed-rule system, which is analogous to the Data Oriented Parsing (DOP) approach in parsing (Bod, 2003)',\n",
       "   'CTS': {'aakansha': [143], 'swastika': [143], 'sweta': [143]}},\n",
       "  6: {'Citing Article': 'P04-1013',\n",
       "   'Citation Text': 'Our best performing model is more accurate than all these previous models except (Bod, 2003)',\n",
       "   'CTS': {'aakansha': [140, 141], 'swastika': [146], 'sweta': [145]}},\n",
       "  7: {'Citing Article': 'P04-1013',\n",
       "   'Citation Text': 'Performance of the latter model on the standard test set achieves 90.1% F-measure on constituents, which is the second best current accuracy level, and only 0.6% below the current best (Bod, 2003)',\n",
       "   'CTS': {'aakansha': [140], 'swastika': [140], 'sweta': [134]}},\n",
       "  10: {'Citing Article': 'E06-2025',\n",
       "   'Citation Text': 'Similarly, (Bod, 2003) changes the way frequencies fi are counted, with a similar effect',\n",
       "   'CTS': {'aakansha': [102, 103], 'swastika': [], 'sweta': [22]}},\n",
       "  12: {'Citing Article': 'W06-2905',\n",
       "   'Citation Text': 'My approach is closely related to work in statistical parsing known as Data-Oriented Parsing (DOP), an empirically highly successful approach with labeled recall and precision scores on the Penn Tree Bank that are among the best currently obtained (Bod, 2003)',\n",
       "   'CTS': {'aakansha': [140], 'swastika': [105], 'sweta': [133]}},\n",
       "  13: {'Citing Article': 'W06-2905',\n",
       "   'Citation Text': 'We approximated the most probable parse as follows (following (Bod, 2003))',\n",
       "   'CTS': {'aakansha': [], 'swastika': [], 'sweta': [25]}},\n",
       "  14: {'Citing Article': 'P05-1022',\n",
       "   'Citation Text': \"This result is only slightly higher than the highest reported result for this test-set, Bod's (.907) (Bod,2003)\",\n",
       "   'CTS': {'aakansha': [140], 'swastika': [140], 'sweta': [38]}},\n",
       "  16: {'Citing Article': 'P07-1051',\n",
       "   'Citation Text': 'This assumption is in consonance with the principle of simplicity, but there are also empirical reasons for the shortest derivation assumption: in Bod (2003) and Hearne and Way (2006), it is shown that DOP models that select the preferred parse of a test sentence using the shortest derivation criterion perform very well',\n",
       "   'CTS': {'aakansha': [46], 'swastika': [100], 'sweta': [100]}},\n",
       "  17: {'Citing Article': 'P07-1051',\n",
       "   'Citation Text': 'But equally important is the fact that this new DOP* model does not suffer from a decrease in parse accuracy if larger subtrees are included, whereas the original DOP model needs to be redressed by a correction factor to maintain this property (Bod 2003)',\n",
       "   'CTS': {'aakansha': [85, 86], 'swastika': [30], 'sweta': [32]}},\n",
       "  18: {'Citing Article': 'P07-1051',\n",
       "   'Citation Text': \"Of course, it is well-known that a supervised parser's f-score decreases if it is transferred to another domain: for example, the (non-binarized) WSJ-trained DOP model in Bod (2003) decreases from around 91% to 85.5% f score if tested on the Brown corpus\",\n",
       "   'CTS': {'aakansha': [], 'swastika': [], 'sweta': [130]}},\n",
       "  19: {'Citing Article': 'W04-0305',\n",
       "   'Citation Text': 'A moderately larger vocabulary version (4215 tag-word pairs) of this parser achieves 89.8% F-measure on section 0, where the best current result on the testing set is 90.7% (Bod, 2003)',\n",
       "   'CTS': {'aakansha': [140], 'swastika': [140], 'sweta': [140]}},\n",
       "  20: {'Citing Article': 'P06-1109',\n",
       "   'Citation Text': 'This subtree probability is redressed by a simple correction factor discussed in Goodman (2003: 136) and Bod (2003)',\n",
       "   'CTS': {'aakansha': [115], 'swastika': [30], 'sweta': [27]}}},\n",
       " 'J01-2004': {1: {'Citing Article': 'W05-0104',\n",
       "   'Citation Text': 'Second, their language models were used to rescore n-best speech lists (supplied by Brian Roark, see Roark (2001))',\n",
       "   'CTS': {'aakansha': [372], 'swastika': [372], 'sweta': [372]}},\n",
       "  2: {'Citing Article': 'P08-1013',\n",
       "   'Citation Text': 'Other linguistically inspired language models like Chelba and Jelinek (2000) and Roark (2001) have been applied to continuous speech recognition',\n",
       "   'CTS': {'aakansha': [17], 'swastika': [15], 'sweta': [40, 41, 42]}},\n",
       "  4: {'Citing Article': 'P04-1015',\n",
       "   'Citation Text': 'The perceptron approach was implemented with the same feature set as that of an existing generative model (Roark, 2001a), and experimental results show that it gives competitive performance to the generative model on parsing the Penn treebank',\n",
       "   'CTS': {'aakansha': [21], 'swastika': [31], 'sweta': [25]}},\n",
       "  5: {'Citing Article': 'P04-1015',\n",
       "   'Citation Text': 'We implemented the perceptron approach with the same feature set as that of an existing generative model (Roark, 2001a), and show that the perceptron model gives performance competitive to that of the generative model on parsing the Penn treebank, thus demonstrating that an unnormalized discriminative parsing model can be applied with heuristic search',\n",
       "   'CTS': {'aakansha': [21], 'swastika': [31], 'sweta': [364]}},\n",
       "  6: {'Citing Article': 'P04-1015',\n",
       "   'Citation Text': 'In the current paper we explore alternatives to reranking approaches, namely heuristic methods for finding the argmax, specifically incremental beam-search strategies related to the parsers of Roark (2001a) and Ratnaparkhi (1999)',\n",
       "   'CTS': {'aakansha': [302], 'swastika': [31], 'sweta': [302]}},\n",
       "  7: {'Citing Article': 'P04-1015',\n",
       "   'Citation Text': 'The parser is an incremental beam-search parser very similar to the sort described in Roark (2001a; 2004), with some changes in the search strategy to accommodate the perceptron feature weights',\n",
       "   'CTS': {'aakansha': [31], 'swastika': [31], 'sweta': [31]}},\n",
       "  9: {'Citing Article': 'P04-1015',\n",
       "   'Citation Text': 'Unlike in Roark (2001a; 2004), there is no look-ahead statistic, so we modified the feature set from those papers to explicitly include the lexical item and POS tag of the next word',\n",
       "   'CTS': {'aakansha': [79, 80], 'swastika': [215], 'sweta': [231]}},\n",
       "  10: {'Citing Article': 'P05-1022',\n",
       "   'Citation Text': 'A good example of this is the Roark parser (Roark, 2001) which works left-to-right through the sentence, and abjures dynamic programming in favor of a beam search, keeping some large number of possibilities to extend by adding the next word, and then re-pruning',\n",
       "   'CTS': {'aakansha': [21], 'swastika': [302], 'sweta': [297]}},\n",
       "  11: {'Citing Article': 'P05-1022',\n",
       "   'Citation Text': \"At the end one has a beam-width's number of best parses (Roark, 2001)\",\n",
       "   'CTS': {'aakansha': [138], 'swastika': [], 'sweta': [133]}},\n",
       "  12: {'Citing Article': 'P05-1022',\n",
       "   'Citation Text': 'To put this in perspective, Roark (Roark, 2001) reports oracle results of 0.941 (with the same experimental setup) using his parser to return a variable number of parses',\n",
       "   'CTS': {'aakansha': [291], 'swastika': [], 'sweta': [291]}},\n",
       "  13: {'Citing Article': 'P04-1006',\n",
       "   'Citation Text': 'The n-best lists were provided by Brian Roark (Roark, 2001)',\n",
       "   'CTS': {'aakansha': [372], 'swastika': [372], 'sweta': [355]}},\n",
       "  14: {'Citing Article': 'P05-1063',\n",
       "   'Citation Text': 'Incremental top-down and left-corner parsing (Roark, 2001a; Roark, 2001b) and head-driven parsing (Charniak, 2001) approaches have directly used generative PCFG models as language models',\n",
       "   'CTS': {'aakansha': [209, 210], 'swastika': [31], 'sweta': [59]}},\n",
       "  15: {'Citing Article': 'W10-2009',\n",
       "   'Citation Text': 'Levy, on the other hand, argued that studies of probabilistic parsing reveal that typically a small number of analyses are assigned the majority of probability mass (Roark, 2001)',\n",
       "   'CTS': {'aakansha': [372], 'swastika': [100], 'sweta': [100]}},\n",
       "  17: {'Citing Article': 'D09-1034',\n",
       "   'Citation Text': 'For example, in Demberg and Keller (2008), trials were run deriving surprisal from the Roark (2001) parser under two different conditions: fully lexicalized parsing, and fully unlexicalized parsing (to pre-terminal part-of-speech tags)',\n",
       "   'CTS': {'aakansha': [], 'swastika': [], 'sweta': []}},\n",
       "  18: {'Citing Article': 'D09-1034',\n",
       "   'Citation Text': 'We modified the Roark (2001) parser to calculate the discussed measures, and the empirical results in ?4 show several things, including: 1) using a fully lexicalized parser to calculate syntactic surprisal and entropy provides higher predictive utility for reading times than these measures calculated via unlexicalized parsing (as in Demberg and Keller); and 2) syntactic entropy is a useful predictor of reading time',\n",
       "   'CTS': {'aakansha': [20, 21, 32], 'swastika': [], 'sweta': [108]}},\n",
       "  19: {'Citing Article': 'D09-1034',\n",
       "   'Citation Text': 'In this section, we review relevant details of the Roark (2001) incremental top-down parser, as configured for use here',\n",
       "   'CTS': {'aakansha': [31], 'swastika': [31], 'sweta': [31]}},\n",
       "  20: {'Citing Article': 'D09-1034',\n",
       "   'Citation Text': 'At each word in the string, the Roark (2001) top-down parser provides access to the weighted set of partial analyses in the beam; the set of complete derivations consistent with these is not immediately accessible, hence additional work is required to calculate such measures',\n",
       "   'CTS': {'aakansha': [33], 'swastika': [21], 'sweta': [31]}}},\n",
       " 'P04-1036': {1: {'Citing Article': 'W04-0837',\n",
       "   'Citation Text': 'The first sense heuristic which is often used as a baseline for supervised WSD systems outperforms many of these systems which take surrounding context into account (McCarthy et al, 2004)',\n",
       "   'CTS': {'aakansha': [8], 'swastika': [8], 'sweta': [8], 'vardha': [8]}},\n",
       "  2: {'Citing Article': 'W04-0837',\n",
       "   'Citation Text': 'Whilst a first sense heuristic based on a sense-tagged corpus such as SemCor is clearly useful, there is a case for obtaining a first, or predominant, sense from untagged corpus data so that a WSD system can be tuned to a given genre or domain (McCarthy et al., 2004) and also because there will be words that occur with insufficient frequency in the hand-tagged resources available',\n",
       "   'CTS': {'aakansha': [15], 'swastika': [15], 'sweta': [82], 'vardha': [15]}},\n",
       "  3: {'Citing Article': 'W04-0837',\n",
       "   'Citation Text': 'The method is described in (McCarthy et al, 2004), which we summarise here',\n",
       "   'CTS': {'aakansha': [41], 'swastika': [68], 'sweta': [64], 'vardha': [45]}},\n",
       "  5: {'Citing Article': 'I08-2105',\n",
       "   'Citation Text': 'McCarthy et al (2004) use a corpus and word similarities to induce a ranking of word senses from an untagged corpus to be used in WSD',\n",
       "   'CTS': {'aakansha': [4], 'swastika': [83], 'sweta': [172], 'vardha': [66]}},\n",
       "  6: {'Citing Article': 'I08-2105',\n",
       "   'Citation Text': 'Previous research in inducing sense rankings from an untagged corpus (McCarthy et al, 2004), and inducing selectional preferences at the word level (for other applications) (Erk, 2007) will provide the starting point for research in this direction',\n",
       "   'CTS': {'aakansha': [15],\n",
       "    'swastika': [15],\n",
       "    'sweta': [153],\n",
       "    'vardha': [126]}},\n",
       "  7: {'Citing Article': 'I08-2105',\n",
       "   'Citation Text': 'McCarthy et al (2004) report a disambiguation precision of 53.0% and recall of 49.0% on the Senseval-2 test data, using an approach that derives sense ranking based on word similarity and distributional analysis in a corpus',\n",
       "   'CTS': {'aakansha': [180, 181],\n",
       "    'swastika': [101],\n",
       "    'sweta': [1],\n",
       "    'vardha': [101]}},\n",
       "  8: {'Citing Article': 'P06-1012',\n",
       "   'Citation Text': 'Research by (McCarthy et al, 2004) highlighted that the sense priors of a word in a corpus depend on the domain from which the corpus is drawn',\n",
       "   'CTS': {'aakansha': [126],\n",
       "    'swastika': [126],\n",
       "    'sweta': [165],\n",
       "    'vardha': [126]}},\n",
       "  9: {'Citing Article': 'P06-1012',\n",
       "   'Citation Text': 'In addition, we implemented the unsupervised method of (McCarthy et al, 2004), which calculates a prevalence score for each sense of a word to predict the predominant sense',\n",
       "   'CTS': {'aakansha': [48],\n",
       "    'swastika': [8],\n",
       "    'sweta': [171],\n",
       "    'vardha': [115]}},\n",
       "  11: {'Citing Article': 'P10-1155',\n",
       "   'Citation Text': 'McCarthy et al (2004) reported that the best results were obtained using k= 50 neighbors and the Wordnet Similarity jcn measure (Jiang and Conrath, 1997)',\n",
       "   'CTS': {'aakansha': [169],\n",
       "    'swastika': [83],\n",
       "    'sweta': [89],\n",
       "    'vardha': [89]}},\n",
       "  12: {'Citing Article': 'W12-3401',\n",
       "   'Citation Text': 'In doing so, we provide first results on the application to French parsing of WordNet automatic sense ranking (ASR), using the method of McCarthy et al (2004)',\n",
       "   'CTS': {'aakansha': [171],\n",
       "    'swastika': [126],\n",
       "    'sweta': [172],\n",
       "    'vardha': [137]}},\n",
       "  13: {'Citing Article': 'W12-3401',\n",
       "   'Citation Text': \"We then use a distributional thesaurus to perform ASR, which determines the prevalence with respect to x of each senses' Sx, following the approach of McCarthy et al (2004)\",\n",
       "   'CTS': {'aakansha': [171],\n",
       "    'swastika': [46],\n",
       "    'sweta': [189],\n",
       "    'vardha': [75]}},\n",
       "  14: {'Citing Article': 'W12-3401',\n",
       "   'Citation Text': 'As explained in Section 2.2, ASR is performed using the method of McCarthy et al (2004)',\n",
       "   'CTS': {'aakansha': [115],\n",
       "    'swastika': [126],\n",
       "    'sweta': [87],\n",
       "    'vardha': [155]}},\n",
       "  16: {'Citing Article': 'S12-1097',\n",
       "   'Citation Text': 'This approach is commonly used as a baseline for word sense disambiguation (McCarthy et al, 2004)',\n",
       "   'CTS': {'aakansha': [8], 'swastika': [8], 'sweta': [1], 'vardha': [8]}},\n",
       "  17: {'Citing Article': 'W10-2803',\n",
       "   'Citation Text': 'More radical solutions than sense grouping that have been proposed are to restrict the task to determining predominant sense in a given domain (McCarthy et al, 2004), or to work directly with para phrases (McCarthy and Navigli, 2009)',\n",
       "   'CTS': {'aakansha': [126],\n",
       "    'swastika': [105],\n",
       "    'sweta': [89],\n",
       "    'vardha': [155]}},\n",
       "  18: {'Citing Article': 'W08-2107',\n",
       "   'Citation Text': 'In addition, we can also infer a positive contribution of the frequency of a sense with the choice of the first synset returned by Word net resulting in a reasonable WSD heuristic (which is compatible with the results by McCarthy et al (2004))',\n",
       "   'CTS': {'aakansha': [180, 181],\n",
       "    'swastika': [13],\n",
       "    'sweta': [137],\n",
       "    'vardha': [68]}},\n",
       "  19: {'Citing Article': 'D07-1026',\n",
       "   'Citation Text': 'It is worthwhile to remark here that, being the IBLE algorithm fully unsupervised, improving the most frequent baseline is an excellent result, rarely achieved in the literature on unsupervised methods for WSD (McCarthy et al, 2004)',\n",
       "   'CTS': {'aakansha': [180],\n",
       "    'swastika': [13],\n",
       "    'sweta': [63],\n",
       "    'vardha': [13]}},\n",
       "  20: {'Citing Article': 'W12-2429',\n",
       "   'Citation Text': 'The first, most frequent sense (MFS) (McCarthy et al, 2004), is widely used baseline for supervised WSD systems',\n",
       "   'CTS': {'aakansha': [41], 'swastika': [8], 'sweta': [159], 'vardha': [8]}}},\n",
       " 'P05-1013': {1: {'Citing Article': 'W05-1505',\n",
       "   'Citation Text': 'Recent work by Nivre and Nilsson introduces a technique where the projectivization transformation is encoded in the non-terminals of constituents during parsing (Nivre and Nilsson, 2005)',\n",
       "   'CTS': {'aakansha': [20], 'swastika': [49], 'vardha': [20]}},\n",
       "  2: {'Citing Article': 'P08-1006',\n",
       "   'Citation Text': \"Sagae and Tsujii (2007)'s dependency parser, based on a probabilistic shift-reduce algorithm extended by the pseudo-projective parsing technique (Nivre and Nilsson, 2005)\",\n",
       "   'CTS': {'aakansha': [24], 'swastika': [109], 'vardha': [9]}},\n",
       "  3: {'Citing Article': 'W10-1401',\n",
       "   'Citation Text': 'Bengoetxea and Gojenola (2010) discuss non-projective dependencies in Basque and show that the pseudo-projective transformation of (Nivre and Nilsson, 2005) improves accuracy for dependency parsing of Basque',\n",
       "   'CTS': {'aakansha': [106], 'swastika': [95], 'vardha': [104]}},\n",
       "  4: {'Citing Article': 'P12-3029',\n",
       "   'Citation Text': 'For tree banks with non-projective trees we use the pseudo-projective parsing technique to transform the tree bank into projective structures (Nivre and Nilsson, 2005)',\n",
       "   'CTS': {'aakansha': [86], 'swastika': [79], 'vardha': [104]}},\n",
       "  5: {'Citing Article': 'W10-1403',\n",
       "   'Citation Text': 'It uses graph transformation to handle non-projective trees (Nivre and Nilsson, 2005)',\n",
       "   'CTS': {'aakansha': [20], 'swastika': [109], 'vardha': [109]}},\n",
       "  6: {'Citing Article': 'D08-1008',\n",
       "   'Citation Text': 'To simplify implementation, we instead opted for the pseudo-projective approach (Nivre and Nilsson, 2005), in which non projective links are lifted upwards in the tree to achieve projectivity, and special trace labels are used to enable recovery of the non projective links at parse time',\n",
       "   'CTS': {'aakansha': [36], 'swastika': [38], 'vardha': [95]}},\n",
       "  7: {'Citing Article': 'D07-1013',\n",
       "   'Citation Text': 'Nivre and Nilsson (2005) showed how the restriction to projective dependency graphs could be lifted by using graph transformation techniques to preprocess training data and post-process parser output, so-called pseudo-projective parsing',\n",
       "   'CTS': {'aakansha': [109], 'swastika': [109], 'vardha': [20]}},\n",
       "  8: {'Citing Article': 'D07-1119',\n",
       "   'Citation Text': 'For handling non-projective relations, Nivre and Nilsson (2005) suggested applying a preprocessing step to a dependency parser, which consists in lifting non-projective arcs to their head repeatedly, until the tree becomes pseudo-projective',\n",
       "   'CTS': {'aakansha': [36], 'swastika': [79], 'vardha': [36]}},\n",
       "  9: {'Citing Article': 'N07-1050',\n",
       "   'Citation Text': 'The most popular strategy for capturing non projective structures in data-driven dependency parsing is to apply some kind of post-processing to the output of a strictly projective dependency parser, as in pseudo-projective parsing (Nivre and Nilsson, 2005), corrective modeling (Hall and Nova? k, 2005), or approximate non-projective parsing (McDonald and Pereira, 2006)',\n",
       "   'CTS': {'aakansha': [23], 'swastika': [109], 'vardha': [62]}},\n",
       "  10: {'Citing Article': 'W09-1207',\n",
       "   'Citation Text': 'We adopt the pseudo-projective approach introduced in (Nivre and Nilsson, 2005) to handle the non-projective languages including Czech, German and English',\n",
       "   'CTS': {'aakansha': [24], 'swastika': [109], 'vardha': [104]}},\n",
       "  11: {'Citing Article': 'E09-1034',\n",
       "   'Citation Text': \"However, just as it has been noted that most non-projective structures appearing in practice are only 'slightly' non projective (Nivre and Nilsson, 2005), we characterise a sense in which the structures appearing in tree banks can be viewed as being only 'slightly' ill-nested\",\n",
       "   'CTS': {'aakansha': [80, 81], 'swastika': [109], 'vardha': [23]}},\n",
       "  12: {'Citing Article': 'W09-1218',\n",
       "   'Citation Text': 'In order to avoid losing the benefits of higher-order parsing, we considered applying pseudo-projective transformation (Nivre and Nilsson, 2005)',\n",
       "   'CTS': {'aakansha': [24], 'swastika': [], 'vardha': [104]}},\n",
       "  13: {'Citing Article': 'C08-1081',\n",
       "   'Citation Text': 'Pseudo-projective parsing for recovering non projective structures (Nivre and Nilsson, 2005)',\n",
       "   'CTS': {'aakansha': [20], 'swastika': [86], 'vardha': [95]}},\n",
       "  14: {'Citing Article': 'C08-1081',\n",
       "   'Citation Text': 'Although the parser only derives projective graphs, the fact that these graphs are labeled allows non-projective dependencies to be captured using the pseudo-projective approach of Nivre and Nilsson (2005) (section 3.4)',\n",
       "   'CTS': {'aakansha': [24], 'swastika': [95], 'vardha': [96]}},\n",
       "  15: {'Citing Article': 'C08-1081',\n",
       "   'Citation Text': 'Pseudo-projective parsing was proposed by Nivreand Nilsson (2005) as a way of dealing with non projective structures in a projective data-driven parser',\n",
       "   'CTS': {'aakansha': [20], 'swastika': [109], 'vardha': [95]}},\n",
       "  16: {'Citing Article': 'C08-1081',\n",
       "   'Citation Text': 'We projectivize training data by a minimal transformation, lifting non-projective arcs one step at a time, and extending the arc label of lifted arcs using the encoding scheme called HEAD by Nivre and Nilsson (2005), which means that a lifted arc is assigned the label r? h, where r is the original label and h is the label of the original head in the non-projective dependency graph',\n",
       "   'CTS': {'aakansha': [49], 'swastika': [51], 'vardha': [40]}},\n",
       "  17: {'Citing Article': 'D11-1006',\n",
       "   'Citation Text': 'For tree banks with non-projective trees we use the pseudo-projective parsing technique to transform the tree bank into projective structures (Nivre and Nilsson, 2005)',\n",
       "   'CTS': {'aakansha': [109], 'swastika': [99], 'vardha': [7]}},\n",
       "  18: {'Citing Article': 'P11-2121',\n",
       "   'Citation Text': 'Since the number of non-projective dependencies is much smaller than the number of projective dependencies (Nivre and Nilsson, 2005), it is not efficient to perform non-projective parsing for all cases',\n",
       "   'CTS': {'aakansha': [14], 'swastika': [7], 'vardha': [14]}},\n",
       "  19: {'Citing Article': 'E06-1010',\n",
       "   'Citation Text': 'It should be noted that the proportion of lost dependencies is about twice as high as the proportion of dependencies that are non-projective in themselves (Nivre and Nilsson, 2005)',\n",
       "   'CTS': {'aakansha': [], 'swastika': [], 'vardha': [49]}},\n",
       "  20: {'Citing Article': 'D07-1111',\n",
       "   'Citation Text': 'The resulting algorithm is projective, and nonprojectivity is handled by pseudo-projective transformations as described in (Nivre and Nilsson, 2005)',\n",
       "   'CTS': {'aakansha': [20], 'swastika': [2], 'vardha': [104]}}},\n",
       " 'P08-1028': {1: {'Citing Article': 'D08-1094',\n",
       "   'Citation Text': 'Mitchell and Lapata (2008) propose a framework to represent the meaning of the combination p+ a as a function f operating on four components: c= f (p, a, R, K) (3) R is the relation holding between p and a, and K additional knowledge',\n",
       "   'CTS': {'aakansha': [51], 'swastika': [21], 'sweta': [65]}},\n",
       "  4: {'Citing Article': 'P14-1060',\n",
       "   'Citation Text': 'While works such as the SDSM model suffer from the problem of sparsity in composing structures beyond bigrams and trigrams, methods such as Mitchell and Lapata (2008) and (Socher et al, 2012) and Grefenstette and Sadrzadeh (2011) are restricted by significant model biases in representing semantic com position by generic algebraic operations',\n",
       "   'CTS': {'aakansha': [], 'swastika': [189], 'sweta': [42]}},\n",
       "  6: {'Citing Article': 'P10-1097',\n",
       "   'Citation Text': 'Mitchell and Lapata (2008), henceforth M& amp; L, propose a general framework in which meaning representations for complex expressions are computed compositionally by combining the vector representations of the individual words of the complex expression',\n",
       "   'CTS': {'aakansha': [189, 190], 'swastika': [53], 'sweta': [21]}},\n",
       "  7: {'Citing Article': 'P10-1097',\n",
       "   'Citation Text': 'Interestingly, Mitchell and Lapata (2008) came to the same result in a different setting',\n",
       "   'CTS': {'aakansha': [185, 186], 'swastika': [], 'sweta': [195]}},\n",
       "  8: {'Citing Article': 'D11-1094',\n",
       "   'Citation Text': 'And Mitchell and Lapata (2008) propose a model for vector composition, focusing on the different functions that might be used to combine the constituent vectors',\n",
       "   'CTS': {'aakansha': [51], 'swastika': [76], 'sweta': [25]}},\n",
       "  9: {'Citing Article': 'W11-0131',\n",
       "   'Citation Text': 'Mitchell and Lapata (2008) provide a general framework for semantic vector composition: p= f (u, v, R, K) (1) 295 where u and v are the vectors to be composed, R is syntactic context, K is a semantic knowledge base, and p is a resulting composed vector (or tensor)',\n",
       "   'CTS': {'aakansha': [189, 190], 'swastika': [57], 'sweta': [25]}},\n",
       "  10: {'Citing Article': 'W11-0131',\n",
       "   'Citation Text': 'As Mitchell and Lapata (2008) did, let us temporarily suspend discussion on what semantics populate our vectors for now',\n",
       "   'CTS': {'aakansha': [48], 'swastika': [], 'sweta': [57]}},\n",
       "  11: {'Citing Article': 'P13-2083',\n",
       "   'Citation Text': 'Mitchell and Lapata (2008) propose a framework to define the composition c= f (a, b, r, K) where r is the relation between a and b, and K is the additional knowledge used to define composition',\n",
       "   'CTS': {'aakansha': [53, 57], 'swastika': [57], 'sweta': [51]}},\n",
       "  12: {'Citing Article': 'P13-2083',\n",
       "   'Citation Text': 'As our final set of baselines, we extend two simple techniques proposed by (Mitchell and Lapata, 2008) that use element-wise addition and multiplication operators to perform composition',\n",
       "   'CTS': {'aakansha': [68, 69, 70], 'swastika': [190], 'sweta': [190]}},\n",
       "  13: {'Citing Article': 'P10-1021',\n",
       "   'Citation Text': 'Although this model has been shown to successfully simulate single and multiple-word priming (McDonald and Brew 2004), it failed to predict processing costs in the Embra eye-tracking corpus (McDonald and Shillcock 2003). In this work we model semantic constraint using the representational framework put forward in Mitchell and Lapata (2008)',\n",
       "   'CTS': {'aakansha': [189, 190], 'swastika': [60], 'sweta': [29]}},\n",
       "  14: {'Citing Article': 'P10-1021',\n",
       "   'Citation Text': 'Mitchell and Lapata (2008) show that several additive and multiplicative models can be formulated under this framework, including the well known tensor products (Smolensky 1990) and circular convolution (Plate 1995)',\n",
       "   'CTS': {'aakansha': [189, 190], 'swastika': [190], 'sweta': [38]}},\n",
       "  15: {'Citing Article': 'W11-0115',\n",
       "   'Citation Text': 'Mitchell and Lapata (2008) introduce a whole family of models of compositionality based on vector addition and point wise-multiplication (and a weighted combination of both), evaluated on a sentence similarity task inspired by Kintsch (2001)',\n",
       "   'CTS': {'aakansha': [24, 25], 'swastika': [190], 'sweta': [51]}},\n",
       "  16: {'Citing Article': 'W11-0115',\n",
       "   'Citation Text': 'The approach proposed by Guevara (2010) is really only an extension of the full additive model of Mitchell and Lapata (2008), the only difference being that adopting a supervised learning methodology ensures that the weight parameters in the function are estimated optimally by linear regression',\n",
       "   'CTS': {'aakansha': [64], 'swastika': [73], 'sweta': [64]}},\n",
       "  17: {'Citing Article': 'W11-0115',\n",
       "   'Citation Text': 'For example, Mitchell and Lapata (2008) use their models to approximate the human ratings in their sentence similarity dataset',\n",
       "   'CTS': {'aakansha': [176, 177], 'swastika': [99], 'sweta': [163]}},\n",
       "  18: {'Citing Article': 'W11-1310',\n",
       "   'Citation Text': 'We use other WSM settings following Mitchell and Lapata (2008)',\n",
       "   'CTS': {'aakansha': [], 'swastika': [189], 'sweta': []}},\n",
       "  19: {'Citing Article': 'W11-1310',\n",
       "   'Citation Text': 'Mitchell and Lapata (2008) observed that a simple multiplication function modelled compositionality better than addition',\n",
       "   'CTS': {'aakansha': [191], 'swastika': [191], 'sweta': [185]}},\n",
       "  20: {'Citing Article': 'W11-1310',\n",
       "   'Citation Text': 'We use the compositionality functions, simple addition and simple multiplication to build compositional vectors Vwr1+wr2 and Vwr1 ?wr2. These are as described in (Mitchell and Lapata, 2008)',\n",
       "   'CTS': {'aakansha': [24], 'swastika': [190], 'sweta': [190]}},\n",
       "  2: {'Citing Article': 'D08-1094',\n",
       "   'Citation Text': 'In both experiments, we compare the SVS model against the state-of-the art model by Mitchell and Lapata 2008 (henceforth M& amp; L; cf',\n",
       "   'CTS': {'swastika': [27], 'sweta': [75]}}},\n",
       " 'P08-1043': {1: {'Citing Article': 'C10-1045',\n",
       "   'Citation Text': 'Finally, we note that simple weighting gives nearly a 2% F1 improvement, whereas Goldberg and Tsarfaty (2008) found that unweighted lattices were more effective for Hebrew',\n",
       "   'CTS': {'aakansha': [94], 'swastika': [94], 'sweta': [156]}},\n",
       "  2: {'Citing Article': 'P11-1141',\n",
       "   'Citation Text': 'Goldberg and Tsarfaty (2008) showed that a single model for morphological segmentation and syntactic parsing of Hebrew yielded an error reduction of 12% over the best pipelined models',\n",
       "   'CTS': {'aakansha': [4], 'swastika': [4], 'sweta': [4]}},\n",
       "  3: {'Citing Article': 'P10-1074',\n",
       "   'Citation Text': 'Zhang and Clark (2008) built a perceptron-based joint segmenter and part-of-speech (POS) tagger for Chinese, and Toutanova and Cherry (2009) learned a joint model of lemmatization and POS tagging which outperformed a pipelined model. Adler and Elhadad (2006) presented an HMM-based approach for unsupervised joint morphological segmentation and tagging of Hebrew, and Goldberg and Tsarfaty (2008) developed a joint model of segmentation, tagging and parsing of Hebrew, based on lattice parsing',\n",
       "   'CTS': {'aakansha': [19], 'swastika': [94], 'sweta': [70]}},\n",
       "  4: {'Citing Article': 'P11-1089',\n",
       "   'Citation Text': 'Goldberg and Tsarfaty (2008) propose a generative joint model',\n",
       "   'CTS': {'aakansha': [19], 'swastika': [19], 'sweta': [3]}},\n",
       "  5: {'Citing Article': 'W10-1404',\n",
       "   'Citation Text': 'Goldberg and Tsarfaty (2008) concluded that an integrated model of morphological disambiguation and syntactic parsing in Hebrew Treebank parsing improves the results of a pipelined approach',\n",
       "   'CTS': {'aakansha': [4], 'swastika': [19], 'sweta': [51]}},\n",
       "  6: {'Citing Article': 'P11-2124',\n",
       "   'Citation Text': 'Goldberg and Tsarfaty (2008) demonstrated the effectiveness of lattice parsing for jointly performing segmentation and parsing of Hebrew text',\n",
       "   'CTS': {'aakansha': [19], 'swastika': [4], 'sweta': [107]}},\n",
       "  7: {'Citing Article': 'P11-2124',\n",
       "   'Citation Text': 'Following (Goldberg and Tsarfaty, 2008) we deal with the ambiguous affixation patterns in Hebrew by encoding the input sentence as a segmentation lattice',\n",
       "   'CTS': {'aakansha': [69, 70], 'swastika': [105], 'sweta': [14]}},\n",
       "  8: {'Citing Article': 'P12-2002',\n",
       "   'Citation Text': 'The complete set of analyses for this word is provided in Goldberg and Tsarfaty (2008)',\n",
       "   'CTS': {'aakansha': [85], 'swastika': [], 'sweta': [33]}},\n",
       "  9: {'Citing Article': 'D12-1046',\n",
       "   'Citation Text': 'A study that is closely related to ours is (Goldberg and Tsarfaty, 2008), where a single generative model was proposed for joint morphological segmentation and syntactic parsing for Hebrew',\n",
       "   'CTS': {'aakansha': [19], 'swastika': [19], 'sweta': [53]}},\n",
       "  10: {'Citing Article': 'D12-1133',\n",
       "   'Citation Text': 'Models that in addition incorporate morphological analysis and segmentation have been explored by Tsarfaty (2006), Cohen and Smith (2007), and Goldberg and Tsarfaty (2008) with special reference to Hebrew parsing',\n",
       "   'CTS': {'aakansha': [19], 'swastika': [19], 'sweta': [48]}},\n",
       "  11: {'Citing Article': 'E09-1038',\n",
       "   'Citation Text': 'Parsing and segmentation are handled jointly by the parser (Goldberg and Tsarfaty, 2008)',\n",
       "   'CTS': {'aakansha': [19], 'swastika': [163], 'sweta': [141]}},\n",
       "  12: {'Citing Article': 'E09-1038',\n",
       "   'Citation Text': 'It is the same grammar as described in (Goldberg and Tsarfaty, 2008)',\n",
       "   'CTS': {'aakansha': [21], 'swastika': [100], 'sweta': [188]}},\n",
       "  14: {'Citing Article': 'E09-1038',\n",
       "   'Citation Text': 'The most recent of which is Goldberg and Tsarfaty (2008), who presented a model based on unweighted lattice parsing for performing the joint task',\n",
       "   'CTS': {'aakansha': [94], 'swastika': [94], 'sweta': [134]}},\n",
       "  15: {'Citing Article': 'E09-1038',\n",
       "   'Citation Text': 'Goldberg and Tsarfaty (2008) use a data-driven morphological analyzer derived from the tree bank',\n",
       "   'CTS': {'aakansha': [133, 134], 'swastika': [188], 'sweta': [156]}},\n",
       "  16: {'Citing Article': 'E09-1038',\n",
       "   'Citation Text': 'The model of Goldberg and Tsarfaty (2008) uses a morphological analyzer to constructs a lattice for each input token',\n",
       "   'CTS': {'aakansha': [85], 'swastika': [86], 'sweta': [5]}},\n",
       "  17: {'Citing Article': 'E09-1038',\n",
       "   'Citation Text': 'Instead, we use the evaluation measure of (Tsarfaty, 2006), also used in (Goldberg and Tsarfaty, 2008), which is an adaptation of parseval to use characters instead of space-delimited tokens as its basic units',\n",
       "   'CTS': {'aakansha': [155], 'swastika': [97]}},\n",
       "  13: {'Citing Article': 'E09-1038',\n",
       "   'Citation Text': 'The most recent of which is Goldberg and Tsarfaty (2008), who presented a model based on unweighted lattice parsing for performing the joint task',\n",
       "   'CTS': {'sweta': [94]}}},\n",
       " 'P08-1102': {1: {'Citing Article': 'C08-1049',\n",
       "   'Citation Text': 'Following Jiang et al (2008), we describe segmentation and Joint S& amp; T as below: For a given Chinese sentence appearing as a character sequence: C 1: n= C 1 C 2.',\n",
       "   'CTS': {'aakansha': [130], 'swastika': [32], 'sweta': [21]}},\n",
       "  2: {'Citing Article': 'C08-1049',\n",
       "   'Citation Text': 'As described in Ng and Low (2004) and Jiang et al (2008), we use s indicating a single character word, while b, m and e indicating the be gin, middle and end of a word respectively',\n",
       "   'CTS': {'aakansha': [], 'swastika': [32], 'sweta': [28]}},\n",
       "  3: {'Citing Article': 'C08-1049',\n",
       "   'Citation Text': 'plates called lexical-target in the column below are introduced by Jiang et al (2008)',\n",
       "   'CTS': {'aakansha': [42], 'swastika': [38], 'sweta': [43]}},\n",
       "  4: {'Citing Article': 'P12-1110',\n",
       "   'Citation Text': 'For CTB-5, we refer to the split by Duan et al (2007) as CTB-5d, and to the split by Jiang et al (2008) as CTB-5j',\n",
       "   'CTS': {'aakansha': [25], 'swastika': [], 'sweta': [92]}},\n",
       "  5: {'Citing Article': 'D12-1126',\n",
       "   'Citation Text': 'Jiang et al (2008) proposes a cascaded linear model for joint Chinese word segmentation and POS tagging',\n",
       "   'CTS': {'aakansha': [130], 'swastika': [92], 'sweta': [9]}},\n",
       "  6: {'Citing Article': 'C10-1135',\n",
       "   'Citation Text': 'We use the feature templates the same as Jiang et al, (2008) to extract features form E model',\n",
       "   'CTS': {'aakansha': [34], 'swastika': [36], 'sweta': [33, 34]}},\n",
       "  8: {'Citing Article': 'P12-1025',\n",
       "   'Citation Text': 'basic processing units are characters which compose words (Jiangetal., 2008a)',\n",
       "   'CTS': {'aakansha': [12], 'swastika': [32], 'sweta': [12]}},\n",
       "  9: {'Citing Article': 'C10-2096',\n",
       "   'Citation Text': 'The solid lines show the 1-best result, which is wrong. Jiang et al (2008b) stress the problems in re ranking phase',\n",
       "   'CTS': {'aakansha': [], 'swastika': [], 'sweta': []}},\n",
       "  10: {'Citing Article': 'C10-2096',\n",
       "   'Citation Text': 'We first segment the Chinese sentences into the 1-best segmentations using a state-of-the-art system (Jiang et al, 2008a), since it is not necessary for a conventional parser to take as input the POS tagging results',\n",
       "   'CTS': {'aakansha': [130], 'swastika': [92], 'sweta': [64]}},\n",
       "  11: {'Citing Article': 'C10-2096',\n",
       "   'Citation Text': 'We first segment and POS tag the Chinese sentences into word lattices using the same system (Jiang et al, 2008a), and prune each lattice into a reasonable size using the marginal probability-based pruning algorithm',\n",
       "   'CTS': {'aakansha': [130], 'swastika': [92], 'sweta': [79]}},\n",
       "  12: {'Citing Article': 'C10-1132',\n",
       "   'Citation Text': 'However, when we repeat the work of (Jiang et al, 2008), which reports to achieve the state-of-art performance in the data-sets that we adopt, it has been found that some features (e.g., C0) are unnoticeably trained several times in their model (which are implicitly generated from different feature templates used in the paper)',\n",
       "   'CTS': {'aakansha': [121], 'swastika': [97], 'sweta': [96]}},\n",
       "  13: {'Citing Article': 'C10-1132',\n",
       "   'Citation Text': 'Table 3: Corpus statistics for the second SIGHAN Bakeoff appears twice, which is generated from two different templates Cn (with n=0, generates C0) and [C0Cn] (used in (Jiang et al, 2008), with n=0, generates [C0C0])',\n",
       "   'CTS': {'aakansha': [37], 'swastika': [91], 'sweta': [91]}},\n",
       "  14: {'Citing Article': 'C10-1132',\n",
       "   'Citation Text': 'As all the features adopted in (Jiang et al, 2008) possess binary values, if a binary feature is repeated n times, then it should behave like a real-valued feature with its value to be n, at least in principle',\n",
       "   'CTS': {'aakansha': [73], 'swastika': [16], 'sweta': [16]}},\n",
       "  15: {'Citing Article': 'C10-1132',\n",
       "   'Citation Text': 'Inspired by (Jiang et al, 2008), we set the real d Although Table 5 has shown that the proposed all the value of C0 to be 2.0, the value of C-1C0anC0C1 to be 3.0, and the values of all other features to be 1.0 for the character-based discriminative-plus model',\n",
       "   'CTS': {'aakansha': [46], 'swastika': [], 'sweta': [35]}},\n",
       "  17: {'Citing Article': 'C10-1132',\n",
       "   'Citation Text': 'Last, (Jiang et al, 2008) 5 adds repeated features implicitly based on (Ng and Low, 2004)',\n",
       "   'CTS': {'aakansha': [12], 'swastika': [34]}},\n",
       "  20: {'Citing Article': 'D12-1046',\n",
       "   'Citation Text': 'Previous joint models mainly focus on word segmentation and POS tagging task, such as the virtual nodes method (Qian et al2010), cascaded linear model (Jiang et al2008a), perceptron (Zhang and Clark, 2008), sub-word based stacked learning (Sun, 2011), re ranking (Jiang et al2008b)',\n",
       "   'CTS': {'aakansha': [130], 'swastika': [92]}},\n",
       "  16: {'Citing Article': 'C10-1132',\n",
       "   'Citation Text': 'Last, (Jiang et al, 2008) 5 adds repeated features implicitly based on (Ng and Low, 2004)',\n",
       "   'CTS': {'sweta': []}}},\n",
       " 'P11-1060': {1: {'Citing Article': 'D11-1039',\n",
       "   'Citation Text': 'Clarke et al (2010) and Liang et al (2011) describe approaches for learning semantic parsers from questions paired with database answers, while Goldwasser et al (2011) presents work on unsupervised learning',\n",
       "   'CTS': {'aakansha': [11], 'swastika': [112], 'sweta': [8]}},\n",
       "  2: {'Citing Article': 'P13-1092',\n",
       "   'Citation Text': 'In particular, Clarke et al (2010) and Liang et al (2011) proposed methods to learn from question answer pairs alone, which represents a significant advance',\n",
       "   'CTS': {'aakansha': [2], 'swastika': [112], 'sweta': [132]}},\n",
       "  3: {'Citing Article': 'P13-1092',\n",
       "   'Citation Text': 'To handle syntax-semantics mismatch, GUSP introduces a novel dependency-based meaning representation. Clarke et al (2010) and Liang et al (2011) used the annotated logical forms to compute answers for their experiments',\n",
       "   'CTS': {'aakansha': [9], 'swastika': [], 'sweta': [25]}},\n",
       "  4: {'Citing Article': 'P13-1092',\n",
       "   'Citation Text': 'More recently, Liang et al (2011) proposed DCS for dependency-based compositional semantics, which represents a semantic parse as a tree with nodes representing database elements and operations, and edges representing relational joins',\n",
       "   'CTS': {'aakansha': [21], 'swastika': [25], 'sweta': [45]}},\n",
       "  5: {'Citing Article': 'P13-1092',\n",
       "   'Citation Text': 'GUSP represents meaning by a semantic tree, which is similar to DCS (Liang et al, 2011)',\n",
       "   'CTS': {'aakansha': [21], 'swastika': [21], 'sweta': [51]}},\n",
       "  6: {'Citing Article': 'W12-2802',\n",
       "   'Citation Text': 'Matuszek et al [2010], Liang et al [2011] and Chen and Mooney [2011] describe models that learn compositional semantics, but word meanings are symbolic structures rather than patterns of features in the external world',\n",
       "   'CTS': {'aakansha': []}},\n",
       "  7: {'Citing Article': 'P13-2009',\n",
       "   'Citation Text': 'It is well-studied in NLP, and a wide variety of methods have been proposed to tackle it ,e.g. rule-based (Popescu et al, 2003), super vised (Zelle, 1995), unsupervised (Goldwasser et al., 2011), and response-based (Liang et al, 2011)',\n",
       "   'CTS': {'aakansha': []}},\n",
       "  8: {'Citing Article': 'D12-1069',\n",
       "   'Citation Text': 'One line of work eliminates the need for an annotated logical form, instead using only the correct answer for a database query (Lianget al 2011) or even a binary correct/incorrect signal (Clarke et al2010)',\n",
       "   'CTS': {'aakansha': [112]}},\n",
       "  9: {'Citing Article': 'N12-1049',\n",
       "   'Citation Text': 'For example, Liang et al (2011) constructs a latent parse similar in structure to a dependency grammar, but representing a logical form',\n",
       "   'CTS': {'aakansha': [11]}},\n",
       "  10: {'Citing Article': 'P12-1045',\n",
       "   'Citation Text': 'Clarke et al (2010) and Liang et al (2011) trained systems on question and answer pairs by automatically finding semantic interpretations of the questions that would generate the correct answers',\n",
       "   'CTS': {'aakansha': [21]}},\n",
       "  11: {'Citing Article': 'P14-1008',\n",
       "   'Citation Text': 'Dependency-based Compositional Semantics (DCS) provides an intuitive way to model semantics of questions, by using simple dependency-like trees (Liang et al, 2011)',\n",
       "   'CTS': {'aakansha': [21]}},\n",
       "  12: {'Citing Article': 'P14-1008',\n",
       "   'Citation Text': 'DCS trees has been proposed to represent natural language semantics with a structure similar to dependency trees (Liang et al, 2011) (Figure 1)',\n",
       "   'CTS': {'aakansha': [10], 'swastika': [21], 'sweta': [25]}},\n",
       "  13: {'Citing Article': 'P14-1008',\n",
       "   'Citation Text': 'In (Liang et al, 2011) DCS trees are learned from QA pairs and database entries',\n",
       "   'CTS': {'aakansha': [36], 'swastika': [47], 'sweta': [94]}},\n",
       "  14: {'Citing Article': 'P14-1008',\n",
       "   'Citation Text': 'Technically, each germ in a DCS tree indicates a variable when the DCS tree is translated to a FOL formula, and the abstract denotation of the germ corresponds to the set of consistent values (Liang et al, 2011) of that variable',\n",
       "   'CTS': {'aakansha': [42], 'swastika': [112], 'sweta': [132]}},\n",
       "  15: {'Citing Article': 'D11-1140',\n",
       "   'Citation Text': 'Clarke et al (2010) and Liang et al (2011) replace semantic annotations in the training set with target answers which are more easily available',\n",
       "   'CTS': {'aakansha': [106]}},\n",
       "  16: {'Citing Article': 'D11-1140',\n",
       "   'Citation Text': 'WASP (Wong and Mooney, 2007), UBL (Kwiatkowski et al, 2010) systems and DCS (Liang et al, 2011)',\n",
       "   'CTS': {'aakansha': [45], 'swastika': [106], 'sweta': [106]}},\n",
       "  17: {'Citing Article': 'P13-1007',\n",
       "   'Citation Text': 'For example, Liang et al (2011) in their state-of-the-art statistical semantic parser within the domain of natural language queries to databases, explicitly devise quantifier scoping in the semantic model',\n",
       "   'CTS': {'aakansha': [88]}},\n",
       "  18: {'Citing Article': 'D11-1022',\n",
       "   'Citation Text': 'DD-ADMM may be useful in other frameworks involving logical constraints, such as the models for compositional semantics presented by Liang et al (2011)',\n",
       "   'CTS': {'aakansha': []}},\n",
       "  19: {'Citing Article': 'P12-1051',\n",
       "   'Citation Text': 'In fact, for any CFG G, it 1See Liang et al (2011) for work in representing lambda calculus expressions with trees',\n",
       "   'CTS': {'aakansha': [171]}},\n",
       "  20: {'Citing Article': 'P12-1051',\n",
       "   'Citation Text': 'In fact, for any CFG G, it 1See Liang et al (2011) for work in representing lambda calculus expressions with trees',\n",
       "   'CTS': {'swastika': [171], 'sweta': [171]}}},\n",
       " 'P11-1061': {1: {'Citing Article': 'P11-1144',\n",
       "   'Citation Text': \"Subramanya et al's model was extended by Das and Petrov (2011) to induce part-of-speech dictionaries for unsupervised learning of taggers\",\n",
       "   'CTS': {'aakansha': [40], 'swastika': [144], 'sweta': [9]}},\n",
       "  2: {'Citing Article': 'P11-1144',\n",
       "   'Citation Text': 'To this end, we use a variant of the quadratic cost criterion of Bengio et al (2006), also used by Subramanya et al (2010) and Das and Petrov (2011)',\n",
       "   'CTS': {'aakansha': [], 'swastika': [], 'sweta': [47]}},\n",
       "  3: {'Citing Article': 'P14-1126',\n",
       "   'Citation Text': 'Fortunately, some recently proposed POS taggers, such as the POS tagger of Das and Petrov (2011), rely only on labeled training data for English and the same kind of parallel text in our approach',\n",
       "   'CTS': {'aakansha': [10], 'swastika': [44], 'sweta': [10]}},\n",
       "  4: {'Citing Article': 'N12-1086',\n",
       "   'Citation Text': 'Applications have ranged from domain adaptation of part-of-speech (POS) taggers (Subramanya et al, 2010), unsupervised learning of POS taggers by using bilingual graph-based projections (Das and Petrov, 2011), and shallow semantic parsing for unknown predicates (Das and Smith,2011)',\n",
       "   'CTS': {'aakansha': [15], 'swastika': [16], 'sweta': [70]}},\n",
       "  5: {'Citing Article': 'N12-1086',\n",
       "   'Citation Text': 'Following Das and Petrov (2011) and Subramanya et al (2010), a similarity score between two trigram types was computed by measuring the cosine similarity between their empirical sentential context statistics',\n",
       "   'CTS': {'aakansha': [25], 'swastika': [44], 'sweta': [52]}},\n",
       "  6: {'Citing Article': 'N12-1086',\n",
       "   'Citation Text': 'Sparsity is desirable in settings where labeled development data for tuning thresholds that select the most probable labels for a given type is unavailable (e.g., Das and Petrov, 2011)',\n",
       "   'CTS': {'aakansha': [29], 'swastika': [110], 'sweta': [83]}},\n",
       "  7: {'Citing Article': 'N12-1052',\n",
       "   'Citation Text': 'Specifically, by replacing fine-grained language specific part-of-speech tags with universal part-of-speech tags, generated with the method described by Das and Petrov (2011), a universal parser is achieved that can be applied to any language for which universal part-of-speech tags are available. Below, we extend this approach to universal parsing by adding cross-lingual word cluster features',\n",
       "   'CTS': {'aakansha': [18], 'swastika': [115], 'sweta': [113]}},\n",
       "  8: {'Citing Article': 'N12-1052',\n",
       "   'Citation Text': 'We study the impact of using cross-lingual cluster features by comparing the strong delexicalized baseline model of McDonald et al (2011), which only has features derived from universal part-of-speech tags, projected from English with the method of Das and Petrov (2011), to the same model when adding features derived from cross-lingual clusters',\n",
       "   'CTS': {'aakansha': [18], 'swastika': [115], 'sweta': [3]}},\n",
       "  9: {'Citing Article': 'N12-1090',\n",
       "   'Citation Text': 'MT-based projection has been applied to various NLP tasks, such as part of-speech tagging (e.g., Das and Petrov (2011)), mention detection (e.g., Zitouni and Florian (2008)), and sentiment analysis (e.g., Mihalcea et al (2007))',\n",
       "   'CTS': {'aakansha': [158], 'swastika': [158], 'sweta': [18]}},\n",
       "  10: {'Citing Article': 'W11-2205',\n",
       "   'Citation Text': 'For example, the multilingual PoS induction approach of Das and Petrov (2011) assumes no supervision for the language whose PoS tags are being 35 induced, but it assumes access to a labeled dataset of a different language. We begin by surveying recent work on unsupervised PoS tagging, focusing on the issue of evaluation (Section 2)',\n",
       "   'CTS': {'aakansha': [21], 'swastika': [23], 'sweta': [13]}},\n",
       "  11: {'Citing Article': 'P13-1155',\n",
       "   'Citation Text': '(Das and Petrov, 2011) used graph-based label propagation for cross-lingual knowledge transfers to induce POS tags between two languages',\n",
       "   'CTS': {'aakansha': [158], 'swastika': [24], 'sweta': [3]}},\n",
       "  12: {'Citing Article': 'D12-1127',\n",
       "   'Citation Text': 'Recent work by Das and Petrov (2011 ) builds a dictionary for a particular language by transferring annotated data from a resource-rich language through the use of word alignments in parallel text',\n",
       "   'CTS': {'aakansha': [21], 'swastika': [10], 'sweta': [120]}},\n",
       "  13: {'Citing Article': 'D12-1127',\n",
       "   'Citation Text': 'These approaches build a dictionary by transferring labeled data from a resource rich language (English) to a resource poor language (Das and Petrov, 2011)',\n",
       "   'CTS': {'aakansha': [10], 'swastika': [], 'sweta': [2]}},\n",
       "  14: {'Citing Article': 'P12-3012',\n",
       "   'Citation Text': 'In recent years research in Natural Language Processing (NLP) has been steadily moving towards multilingual processing: the availability of ever growing amounts of text in different languages, in fact, has been a major driving force behind research on multilingual approaches, from morphosyntactic (Das and Petrov, 2011) and syntactico semantic (Peirsman and Pado?, 2010) phenomena to high-end tasks like textual entailment (Mehdad et al., 2011) and sentiment analysis (Lu et al, 2011)',\n",
       "   'CTS': {'aakansha': [24], 'swastika': [16], 'sweta': [19]}},\n",
       "  15: {'Citing Article': 'D11-1006',\n",
       "   'Citation Text': 'Furthermore, we evaluate with both gold-standard part-of-speech tags, as well as predicted part-of speech tags from the projected part-of-speech tagger of Das and Petrov (2011). This tagger relies only on labeled training data for English, and achieves accuracies around 85% on the languages that we consider',\n",
       "   'CTS': {'aakansha': [17], 'swastika': [23], 'sweta': [153]}},\n",
       "  16: {'Citing Article': 'D11-1006',\n",
       "   'Citation Text': 'In the first, we assumed that the test set for each target language had gold part-of-speech tags, and in the second we used predicted part-of-speech tags from the projection tagger of Das and Petrov (2011), which also uses English as the source language',\n",
       "   'CTS': {'aakansha': [111], 'swastika': [158], 'sweta': [18]}},\n",
       "  17: {'Citing Article': 'P13-2112',\n",
       "   'Citation Text': 'This parallel data can be exploited to bridge languages, and in particular, transfer information from a highly-resourced language to a lesser-resourced language, to build unsupervised POS taggers. In this paper, we propose an unsupervised approach to POS tagging in a similar vein to the work of Das and Petrov (2011)',\n",
       "   'CTS': {'aakansha': [10], 'swastika': [10], 'sweta': [161]}},\n",
       "  18: {'Citing Article': 'P13-2112',\n",
       "   'Citation Text': 'Das and Petrov (2011) achieved the current state-of-the-art for unsupervised tagging by exploiting high confidence alignments to copy tags from the source language to the target language',\n",
       "   'CTS': {'aakansha': [29], 'swastika': [56], 'sweta': [23]}},\n",
       "  19: {'Citing Article': 'P13-2112',\n",
       "   'Citation Text': 'We have proposed a method for unsupervised POS tagging that performs on par with the current state of-the-art (Das and Petrov, 2011), but is substantially less-sophisticated (specifically not requiring convex optimization or a feature-based HMM)',\n",
       "   'CTS': {'aakansha': [161]}},\n",
       "  20: {'Citing Article': 'P13-2112',\n",
       "   'Citation Text': 'We have proposed a method for unsupervised POS tagging that performs on par with the current state of-the-art (Das and Petrov, 2011), but is substantially less-sophisticated (specifically not requiring convex optimization or a feature-based HMM)',\n",
       "   'CTS': {'swastika': [161], 'sweta': [23]}}},\n",
       " 'P87-1015': {1: {'Citing Article': 'P01-1018',\n",
       "   'Citation Text': 'The approach that Vijay-Shanker et al (1987) and Weir (1988) take, elaborated on by Becker et al (1992), is to identify a very general class of formalisms, which they call linear context free rewriting systems (CFRSs), and define for this class a large space of structural descriptions which serves as a common ground in which the strong generative capacities of these formalisms can be compared',\n",
       "   'CTS': {'swastika': [118], 'sweta': [205], 'vardha': [165]}},\n",
       "  2: {'Citing Article': 'E09-1055',\n",
       "   'Citation Text': 'Here we use the standard definition of LCFRS (Vijay-Shanker et al, 1987) and only fix our notation; for a more thorough discussion of this formal ism, we refer to the literature. Let G be an LCFRS',\n",
       "   'CTS': {'swastika': [118], 'sweta': [229], 'vardha': [119]}},\n",
       "  3: {'Citing Article': 'W07-2214',\n",
       "   'Citation Text': 'There are many (structural) mildly context sensitive grammar formalisms ,e.g .mcfg ,lcfrs, mg, and they have been shown to be equivalent (Vijay-Shanker et al., 1987)',\n",
       "   'CTS': {'swastika': [149], 'sweta': [146], 'vardha': [3]}},\n",
       "  4: {'Citing Article': 'P09-2003',\n",
       "   'Citation Text': 'They are in particular more powerful than linear context-free rewriting systems (LCFRS) (Vijay-Shanker et al, 1987)',\n",
       "   'CTS': {'swastika': [], 'sweta': [201], 'vardha': [118]}},\n",
       "  5: {'Citing Article': 'P09-1111',\n",
       "   'Citation Text': 'Following this line, (Vijay-Shanker et al, 1987) have introduced a formalism called linear context-free rewriting systems (LCFRSs) that has received much attention in later years by the community',\n",
       "   'CTS': {'swastika': [118], 'sweta': [151], 'vardha': [118]}},\n",
       "  6: {'Citing Article': 'P09-1111',\n",
       "   'Citation Text': 'We briefly summarize here the terminology and notation that we adopt for LCFRS; for detailed definitions, see (Vijay-Shanker et al, 1987)',\n",
       "   'CTS': {'swastika': [118], 'sweta': [222], 'vardha': [133]}},\n",
       "  7: {'Citing Article': 'P07-1021',\n",
       "   'Citation Text': 'Linear Context-Free Rewriting Systems Gap-restricted dependency languages are closely related to Linear Context-Free Rewriting Systems (lcfrs) (Vijay-Shanker et al, 1987), a class of formal systems that generalizes several mildly context-sensitive grammar formalisms',\n",
       "   'CTS': {'swastika': [2], 'sweta': [22, 23], 'vardha': [138]}},\n",
       "  8: {'Citing Article': 'N09-1061',\n",
       "   'Citation Text': 'This observation is in line with empirical studies in the context of dependency parsing, where the need for formalisms with higher fan-out has been observed even in standard, single language texts (Kuhlmann and Nivre, 2006). In this paper, we present an algorithm that computes optimal decompositions of rules in the formalism of Linear Context-Free Rewriting Systems (LCFRS) (Vijay-Shanker et al, 1987)',\n",
       "   'CTS': {'swastika': [118], 'sweta': [156], 'vardha': [156]}},\n",
       "  9: {'Citing Article': 'N09-1061',\n",
       "   'Citation Text': 'We briefly summarize the terminology and notation that we adopt for LCFRS; for detailed definitions, see Vijay-Shanker et al (1987)',\n",
       "   'CTS': {'swastika': [222], 'sweta': [221], 'vardha': [118]}},\n",
       "  10: {'Citing Article': 'W10-1407',\n",
       "   'Citation Text': 'LCFRS (Vijay-Shanker et al, 1987) are a natural extension of CFG in which a single nonterminal node can dominate more than one continuous span of terminals',\n",
       "   'CTS': {'swastika': [119], 'sweta': [54], 'vardha': [119]}},\n",
       "  11: {'Citing Article': 'W10-1407',\n",
       "   'Citation Text': 'A LCFRS (Vijay-Shanker et al, 1987) is a tuple G= (N, T, V, P, S ) where N is a finite set of non-terminals with a function dim: N? N that determines the fan-out of each A? N; b) T and V are disjoint finite sets of terminals and variables; c) S? N is the start symbol with dim (S)= 1; d) P is a finite set of rewriting rules A (? 1,..',\n",
       "   'CTS': {'swastika': [], 'sweta': [128], 'vardha': [133]}},\n",
       "  12: {'Citing Article': 'E09-1053',\n",
       "   'Citation Text': 'In particular, we cast new light on the relationship between CCG and other mildly context-sensitive formalisms such as Tree-Adjoining Grammar (TAG; Joshi and Schabes (1997)) and Linear Context-Free Rewrite Systems (LCFRS; Vijay-Shanker et al (1987))',\n",
       "   'CTS': {'swastika': [207], 'sweta': [217], 'vardha': [164]}},\n",
       "  13: {'Citing Article': 'E09-1053',\n",
       "   'Citation Text': 'By this result, CCG falls in line with context-free grammars, TAG, and LCFRS, whose sets of derivational structures are all regular (Vijay-Shanker et al., 1987)',\n",
       "   'CTS': {'swastika': [207], 'sweta': [16], 'vardha': [204]}},\n",
       "  14: {'Citing Article': 'E09-1053',\n",
       "   'Citation Text': 'It is important to note that while CCG derivations themselves can be seen as trees as well, they do not always form regular tree languages (Vijay-Shanker et al, 1987)',\n",
       "   'CTS': {'swastika': [19], 'sweta': [16], 'vardha': [9]}},\n",
       "  15: {'Citing Article': 'N10-1035',\n",
       "   'Citation Text': 'On this line of investigation, mildly context-sensitive grammar formalisms have been introduced (Joshi,1985), including, among several others, the tree ad joining grammars (TAGs) of Joshi et al (1975). Linear context-free rewriting system (LCFRS), introduced by Vijay-Shanker et al (1987), is a mildly context-sensitive formalism that allows the derivation of tuples of strings, i.e., discontinuous phrases',\n",
       "   'CTS': {'swastika': [119], 'sweta': [214], 'vardha': [28]}},\n",
       "  16: {'Citing Article': 'P12-1053',\n",
       "   'Citation Text': 'CFTG are weakly equivalent to the simple macro grammars of Fischer (1968), which are a notational variant of the well-nested linear context-free rewriting systems (LCFRS) of Vijay-Shanker et al (1987) and the well-nested multiple context-free grammars (MCFG) of Seki et al (1991)',\n",
       "   'CTS': {'swastika': [118], 'sweta': [35], 'vardha': [138]}}},\n",
       " 'W06-2932': {2: {'Citing Article': 'W06-2920',\n",
       "   'Citation Text': 'Introduce through post-processing ,e.g. through reattachment rules (Bick, 2006) or if the change increases overall parse tree probability (McDonald et al, 2006)',\n",
       "   'CTS': {'swastika': [86], 'sweta': [5], 'vardha': [19]}},\n",
       "  3: {'Citing Article': 'W06-2920',\n",
       "   'Citation Text': 'Table 5 shows the official results for submitted parser outputs. The two participant groups with the highest total score are McDonald et al (2006) and Nivre et al (2006)',\n",
       "   'CTS': {'swastika': [79], 'sweta': [36], 'vardha': [36]}},\n",
       "  4: {'Citing Article': 'W06-2920',\n",
       "   'Citation Text': 'Even though McDonald et al (2006) and Nivre et al (2006) obtained very similar overall scores, a more detailed look at their performance shows clear differences',\n",
       "   'CTS': {'swastika': [79], 'sweta': [61], 'vardha': [57]}},\n",
       "  5: {'Citing Article': 'W08-1007',\n",
       "   'Citation Text': 'The highest score on parsing German in the CoNLL-X shared task was obtained by the system of McDonald et al (2006) with a LAS of 87.34 based on the TIGER tree bank, but we want to stress that these results are not comparable due to different data sets (and a different policy regarding the inclusion of punctuation). The constituency versions were evaluated according to the labeled recall (LR), labeled precision (LP) and labeled F-score (LF)',\n",
       "   'CTS': {'swastika': [79], 'sweta': [76], 'vardha': [76]}},\n",
       "  6: {'Citing Article': 'W09-1210',\n",
       "   'Citation Text': 'McDonald et al (2006) use an additional algorithm',\n",
       "   'CTS': {'swastika': [22], 'sweta': [45], 'vardha': [54]}},\n",
       "  7: {'Citing Article': 'W12-3407',\n",
       "   'Citation Text': 'Regarding the data-driven parsers, we have made use of MaltParser (Nivre et al, 2007b) and MST Parser (McDonald et al, 2006), two state of the art dependency parsers representing two dominant approaches in data-driven dependency parsing, and that have been successfully applied to typologically different languages and tree banks (McDonald and Nivre, 2007)',\n",
       "   'CTS': {'swastika': [54], 'sweta': [106], 'vardha': [104]}},\n",
       "  8: {'Citing Article': 'I08-1012',\n",
       "   'Citation Text': \"In fact, our approach can also be applied to other parsers, such as (Yamada and Matsumoto, 2003)'s parser, (McDonald et al., 2006)'s parser, and so on\",\n",
       "   'CTS': {'swastika': [12], 'sweta': [12], 'vardha': [12]}},\n",
       "  11: {'Citing Article': 'N07-1050',\n",
       "   'Citation Text': 'McDonald et al (2006) use post-processing for non-projective dependencies and for labeling',\n",
       "   'CTS': {'swastika': [22], 'sweta': [64], 'vardha': [22]}},\n",
       "  12: {'Citing Article': 'D07-1122',\n",
       "   'Citation Text': 'As described in (McDonald et al, 2006), we treat the labeling of dependencies as a sequence labeling problem',\n",
       "   'CTS': {'swastika': [41], 'sweta': [41], 'vardha': [41]}},\n",
       "  14: {'Citing Article': 'D07-1015',\n",
       "   'Citation Text': 'It should be noted that McDonald et al (2006) use a richer feature set that is incomparable to our features',\n",
       "   'CTS': {'swastika': [24], 'sweta': [64], 'vardha': [64]}},\n",
       "  18: {'Citing Article': 'D10-1004',\n",
       "   'Citation Text': 'Entries marked with are the highest reported in the literature, to the best of our knowledge, beating (sometimes slightly) McDonald et al (2006), Martins et al (2008), Martins et al (2009), and, in the case of English Proj., also the third-order parser of Koo and Collins (2010), which achieves 93.04% on that dataset (their experiments in Czech are not comparable, since the datasets are different)',\n",
       "   'CTS': {'swastika': [79], 'sweta': [33], 'vardha': []}},\n",
       "  19: {'Citing Article': 'P08-1108',\n",
       "   'Citation Text': 'The specific graph-based model studied in this work is that presented by McDonald et al (2006), which factors scores over pairs of arcs (instead of just single arcs) and uses near exhaustive search for unlabeled parsing coupled with a separate classifier to label each arc. We call this system MSTParser, or simply MST for short, which is also the name of the freely available implementation.',\n",
       "   'CTS': {'swastika': [12], 'sweta': [41], 'vardha': [57]}},\n",
       "  20: {'Citing Article': 'P08-1108',\n",
       "   'Citation Text': 'More precisely, dependency arcs (or pairs of arcs) are first represented by a high dimensional feature vector f (i, j, l) Rk, where f is typically a binary feature vector over properties of the arc as well as the surrounding input (McDonald et al, 2005a; McDonald et al, 2006)',\n",
       "   'CTS': {'swastika': [43], 'sweta': [43], 'vardha': [43]}},\n",
       "  9: {'Citing Article': 'N07-1050',\n",
       "   'Citation Text': 'But whereas the spanning tree parser of McDonald et al (2006) and the pseudo-projective parser of Nivre et al (2006) achieve this performance only with special pre or post-processing, the approach presented here derives a labeled non-projective graph in a single incremental process and hence at least has the advantage of simplicity',\n",
       "   'CTS': {'sweta': [104], 'vardha': [57]}},\n",
       "  10: {'Citing Article': 'N07-1050',\n",
       "   'Citation Text': 'Moreover, it has better time complexity than the approximate second-order spanning tree parsing of McDonald et al (2006), which has exponential complexity in the worst case (although this does not appear to be a problem in practice)',\n",
       "   'CTS': {'sweta': [58], 'vardha': [58]}},\n",
       "  13: {'Citing Article': 'W11-0314',\n",
       "   'Citation Text': 'ULISSE was tested against the output of two really different data driven parsers: the first order Maximum Spanning Tree (MST) parser (McDonald et al., 2006) and the DeSR parser (Attardi, 2006) using Support Vector Machine as learning algorithm',\n",
       "   'CTS': {'sweta': [21], 'vardha': [21]}},\n",
       "  16: {'Citing Article': 'D10-1069',\n",
       "   'Citation Text': 'The dependency parsers that we compare are the deterministic shift-reduce MaltParser (Nivre et al, 2007) and the second-order minimum spanning tree algorithm based MstParser (McDonald et al, 2006)',\n",
       "   'CTS': {'sweta': [104], 'vardha': [21]}}},\n",
       " 'W06-3114': {1: {'Citing Article': 'W06-3120',\n",
       "   'Citation Text': 'The official results were slightly better because a lowercase evaluation was used, see (Koehn and Monz, 2006)',\n",
       "   'CTS': {'aakansha': [170], 'swastika': [47], 'sweta': [108]}},\n",
       "  2: {'Citing Article': 'D07-1092',\n",
       "   'Citation Text': 'We are further focusing on the shared task of the workshop on Statistical Machine Translation, which took place last year (Koehn and Monz, 2006) and consisted in translating Spanish, German, and French texts from and to English',\n",
       "   'CTS': {'aakansha': [8], 'swastika': [8], 'sweta': [34]}},\n",
       "  3: {'Citing Article': 'C08-1074',\n",
       "   'Citation Text': 'For our training and test data we used the English-French subset of the Europarl corpus provided for the shared task (Koehn and Monz, 2006) at the Statistical Machine Translation workshop held in conjunction with the 2006 HLT-NAACL conference',\n",
       "   'CTS': {'aakansha': [9], 'swastika': [18], 'sweta': [18]}},\n",
       "  4: {'Citing Article': 'W07-0718',\n",
       "   'Citation Text': \"The results of last year's workshop further suggested that Bleu systematically underestimated the quality of rule-based machine translation systems (Koehn and Monz, 2006)\",\n",
       "   'CTS': {'aakansha': [36], 'swastika': [], 'sweta': [151]}},\n",
       "  5: {'Citing Article': 'P07-1083',\n",
       "   'Citation Text': 'For the bi text-based annotation, we use publicly available word alignments from the Europarl corpus, automatically generated by GIZA++ for FrenchEnglish (Fr), Spanish-English (Es) and German-English (De) (Koehn and Monz, 2006)',\n",
       "   'CTS': {'aakansha': [9], 'swastika': [18], 'sweta': [16]}},\n",
       "  6: {'Citing Article': 'W07-0738',\n",
       "   'Citation Text': 'Evaluation results recently reported by Callison-Burch et al (2006) and Koehn and Monz (2006), revealed that, in certain cases, the BLEU metric may not be a reliable MTquality indicator',\n",
       "   'CTS': {'aakansha': [36], 'swastika': [144], 'sweta': [172]}},\n",
       "  7: {'Citing Article': 'W07-0738',\n",
       "   'Citation Text': 'For instance, Callison-Burch et al (2006) and Koehn and Monz (2006) reported and analyzed several cases of strong disagreement between system rankings provided by human assessors and those produced by the BLEU metric (Papineni et al, 2001)',\n",
       "   'CTS': {'aakansha': [140], 'swastika': [145], 'sweta': [36]}},\n",
       "  8: {'Citing Article': 'W07-0738',\n",
       "   'Citation Text': 'We present a comparative study on the behavior of several metric representatives from each linguistic level in the context of some of the cases reported by Koehn and Monz (2006) and Callison-Burch et al (2006) (see Section 3)',\n",
       "   'CTS': {'aakansha': [140], 'swastika': [103], 'sweta': [103]}},\n",
       "  9: {'Citing Article': 'W07-0738',\n",
       "   'Citation Text': 'We analyze some of the cases reported by Koehn and Monz (2006) and Callison-Burch et al (2006)',\n",
       "   'CTS': {'aakansha': [140], 'swastika': [], 'sweta': [167]}},\n",
       "  10: {'Citing Article': 'D07-1030',\n",
       "   'Citation Text': 'We use the same method described in (Koehn and Monz, 2006) to perform the significance test',\n",
       "   'CTS': {'aakansha': [102]}},\n",
       "  11: {'Citing Article': 'D07-1030',\n",
       "   'Citation Text': 'We also manually evaluated the RBMT systems and SMT systems in terms of both adequacy and fluency as defined in (Koehn and Monz, 2006)',\n",
       "   'CTS': {'aakansha': [84], 'swastika': [50], 'sweta': [102]}},\n",
       "  12: {'Citing Article': 'W08-0406',\n",
       "   'Citation Text': 'The baseline is the PSMT system used for the 2006 NAACL SMT workshop (Koehn and Monz, 2006) with phrase length 3 and a trigram language model (Stolcke, 2002)',\n",
       "   'CTS': {'aakansha': [11]}},\n",
       "  13: {'Citing Article': 'W11-1002',\n",
       "   'Citation Text': 'Callison-Burch et al (2006) and Koehn and Monz (2006), for example, study situations where BLEU strongly disagrees with human judgment of translation quality',\n",
       "   'CTS': {'aakansha': [140]}},\n",
       "  14: {'Citing Article': 'D07-1091',\n",
       "   'Citation Text': 'The English German systems were trained on the full 751,088 sentence Europarl corpus and evaluated on the WMT 2006 test set (Koehn and Monz, 2006)',\n",
       "   'CTS': {'aakansha': [126]}},\n",
       "  15: {'Citing Article': 'D07-1091',\n",
       "   'Citation Text': 'We report results on the development test set, which is also the out-of-domain test set of the WMT06 workshop shared task (Koehn and Monz, 2006)',\n",
       "   'CTS': {'aakansha': [15], 'swastika': [18], 'sweta': [126]}},\n",
       "  16: {'Citing Article': 'P07-1108',\n",
       "   'Citation Text': 'A shared task to evaluate machine translation performance was organized as part of the NAACL/HLT 2006 Workshop on Statistical Machine Translation (Koehn and Monz, 2006)',\n",
       "   'CTS': {'aakansha': [8]}},\n",
       "  18: {'Citing Article': 'E12-3010',\n",
       "   'Citation Text': 'For the same reason, human evaluation metrics based on adequacy and fluency were not suitable either (Koehn and Monz, 2006)',\n",
       "   'CTS': {'aakansha': [90]}},\n",
       "  19: {'Citing Article': 'W09-0402',\n",
       "   'Citation Text': 'The correlations on the document level were computed on the English, French, Spanish and German texts generated by various translation systems in the framework of the first (Koehn and Monz, 2006), second (Callison-Burch et al, 2007) and third shared translation task (Callison-Burchet al, 2008)',\n",
       "   'CTS': {'aakansha': [5, 6]}},\n",
       "  17: {'Citing Article': 'P07-1108',\n",
       "   'Citation Text': 'A shared task to evaluate machine translation performance was organized as part of the NAACL/HLT 2006 Workshop on Statistical Machine Translation (Koehn and Monz, 2006)',\n",
       "   'CTS': {'swastika': [170], 'sweta': [170]}},\n",
       "  20: {'Citing Article': 'W09-0402',\n",
       "   'Citation Text': 'The correlations on the document level were computed on the English, French, Spanish and German texts generated by various translation systems in the framework of the first (Koehn and Monz, 2006), second (Callison-Burch et al, 2007) and third shared translation task (Callison-Burchet al, 2008)',\n",
       "   'CTS': {'swastika': [145], 'sweta': [8]}}},\n",
       " 'W11-2123': {1: {'Citing Article': 'W11-2138',\n",
       "   'Citation Text': 'We used common tools for phrase-based translation Moses (Koehn et al, 2007) decoder and tools, SRILM (Stolcke, 2002) and KenLM (Heafield, 2011) for language modelling and GIZA++ (Och and Ney, 2000) for word alignments',\n",
       "   'CTS': {'aakansha': [7], 'swastika': [1], 'vardha': [12]}},\n",
       "  2: {'Citing Article': 'P14-2022',\n",
       "   'Citation Text': 'The language model was compiled into KenLM probing format (Heafield, 2011) and placed in RAM while text phrase tables were forced into the disk cache before each run',\n",
       "   'CTS': {'aakansha': [45], 'swastika': [1], 'vardha': [7]}},\n",
       "  3: {'Citing Article': 'W12-3145',\n",
       "   'Citation Text': 'Thus given a fragment tf consisting of a sequence of target tokens, we compute LM scores for (i) < s& gt ;tf, (ii )tf and (iii )tf < /s& gt; and use the best score (only) for pruning. While this increases the number of LM queries, we exploit the language model state in formation in KenLM (Heafield, 2011) to optimize the queries by saving the scores for the unchanged states',\n",
       "   'CTS': {'aakansha': [136], 'swastika': [7], 'vardha': [131]}},\n",
       "  4: {'Citing Article': 'W12-3131',\n",
       "   'Citation Text': 'Our translation system uses cdec (Dyer et al,2010), an implementation of the hierarchical phrase based translation model (Chiang, 2007) that uses the KenLM library (Heafield, 2011) for language model inference',\n",
       "   'CTS': {'aakansha': [1], 'swastika': [1], 'vardha': [21]}},\n",
       "  5: {'Citing Article': 'W12-3154',\n",
       "   'Citation Text': 'The three data sets in use in this paper are summarised in Table 1.The translation systems consisted of phrase tables and lexicalised reordering tables estimated using the standard Moses (Koehn et al, 2007) training pipeline, and 5-gram Kneser-Ney smoothed language models estimated using the SRILM toolkit (Stolcke, 2002), with KenLM (Heafield, 2011) used at runtime',\n",
       "   'CTS': {'aakansha': [7], 'swastika': [1], 'vardha': [21]}},\n",
       "  6: {'Citing Article': 'P12-2058',\n",
       "   'Citation Text': 'The features used are basic lexical features, word penalty and a 3-gram Language Model (Heafield, 2011)',\n",
       "   'CTS': {'aakansha': [8], 'swastika': [52], 'vardha': [108]}},\n",
       "  7: {'Citing Article': 'W11-2139',\n",
       "   'Citation Text': 'Inference was carried out using the language modeling library described by Heafield (2011)',\n",
       "   'CTS': {'aakansha': [1], 'swastika': [1], 'vardha': [129]}},\n",
       "  8: {'Citing Article': 'P13-2003',\n",
       "   'Citation Text': 'We used the MADA ATB segmentation for Arabic (Roth et al, 2008) and true casing for English, phrases of maximal length 7, KneserNey smoothing, and lexicalized reordering (Koehn et al, 2005), and a 5-gram language model, trained on GigaWordv.5 using KenLM (Heafield, 2011)',\n",
       "   'CTS': {'aakansha': [205], 'swastika': [1], 'vardha': [199]}},\n",
       "  9: {'Citing Article': 'W12-3134',\n",
       "   'Citation Text': 'The approach we take is similar to work on efficiently storing large phrase tables by Zens and Ney (2007) and language models by Heafield (2011) and Pauls and Klein (2011)? both language model implementations are now integrated with Joshua',\n",
       "   'CTS': {'aakansha': [274], 'swastika': [7], 'vardha': [52]}},\n",
       "  10: {'Citing Article': 'W12-3134',\n",
       "   'Citation Text': 'Our quantization approach follows Federico and Bertoldi (2006) and Heafield (2011) in partitioning the value histogram into 256 equal-sized buckets',\n",
       "   'CTS': {'aakansha': [204], 'swastika': [177], 'vardha': [263]}},\n",
       "  11: {'Citing Article': 'W12-3134',\n",
       "   'Citation Text': 'With the help of the respective original authors, the language model implementations by Heafield (2011) and Pauls and Klein (2011) have been integrated with Joshua, dropping support for the slower and more difficult to compile SRILM toolkit (Stolcke, 2002)',\n",
       "   'CTS': {'aakansha': [274], 'swastika': [7], 'vardha': [52]}},\n",
       "  12: {'Citing Article': 'W12-3160',\n",
       "   'Citation Text': 'This was used to create a KenLM (Heafield, 2011)',\n",
       "   'CTS': {'aakansha': [1], 'swastika': [1], 'vardha': [1]}},\n",
       "  13: {'Citing Article': 'W12-3706',\n",
       "   'Citation Text': 'In the Opinum system we query the M p, M n models with the KenLM (Heafield, 2011) open-source library because it answers the queries very quickly and has a short loading time, which is suitable for a web application',\n",
       "   'CTS': {'aakansha': [1], 'swastika': [200], 'vardha': [145]}},\n",
       "  14: {'Citing Article': 'W11-2147',\n",
       "   'Citation Text': 'Our base line is a factored phrase based SMT system that uses the Moses toolkit (Koehn et al, 2007) for translation model training and decoding, GIZA++ (Ochand Ney, 2003) for word alignment, SRILM (Stolcke, 2002) an KenLM (Heafield, 2011) for language modelling and minimum error rate training (Och, 2003) to tune model feature weights',\n",
       "   'CTS': {'aakansha': [1], 'swastika': [7], 'vardha': [182]}},\n",
       "  15: {'Citing Article': 'E12-1083',\n",
       "   'Citation Text': 'For language modeling, we computed 5-gram models using IRSTLM7 (Federico et al., 2008) and queried the model with KenLM (Heafield, 2011)',\n",
       "   'CTS': {'aakansha': [1], 'swastika': [200], 'vardha': [274]}},\n",
       "  16: {'Citing Article': 'P12-1002',\n",
       "   'Citation Text': 'Furthermore, the extraction of grammars for training is done in a leave-one-out fashion (Zollmann and Simaan,2005) where rules are extracted for a parallel sentence pair only if the same rules are found in other sentences of the corpus as well.3-gram (news-commentary) and 5-gram (Europarl) language models are trained on the data described in Table 1, using the SRILM toolkit (Stolcke, 2002) and binarized for efficient querying using kenlm (Heafield, 2011)',\n",
       "   'CTS': {'aakansha': [229], 'swastika': [200], 'vardha': [12]}},\n",
       "  17: {'Citing Article': 'D12-1108',\n",
       "   'Citation Text': 'n-gram language model scores implemented with the KenLM toolkit (Heafield, 2011), 3',\n",
       "   'CTS': {'aakansha': [1], 'swastika': [7], 'vardha': [7]}},\n",
       "  18: {'Citing Article': 'P12-2006',\n",
       "   'Citation Text': 'Research efforts to increase search efficiency for phrase-based MT (Koehn et al, 2003) have explored several directions, ranging from generalizing the stack decoding algorithm (Ortiz et al, 2006) to additional early pruning techniques (Delaney et al, 2006), (Moore and Quirk, 2007) and more efficient language model (LM) querying (Heafield, 2011)',\n",
       "   'CTS': {'aakansha': [93], 'swastika': [278], 'vardha': [140]}},\n",
       "  19: {'Citing Article': 'P13-2073',\n",
       "   'Citation Text': 'For English language modeling, we use English Giga word Corpus with 5-gram LM using the KenLM toolkit (Heafield, 2011)',\n",
       "   'CTS': {'aakansha': [1], 'swastika': [7], 'vardha': [199]}},\n",
       "  20: {'Citing Article': 'P13-1109',\n",
       "   'Citation Text': 'For the language model, we used the KenLM toolkit (Heafield, 2011) to create a 5-gram language model on the target side of the Europarl corpus (v7) with approximately 54M tokens with KneserNey smoothing',\n",
       "   'CTS': {'aakansha': [199], 'swastika': [7], 'vardha': [199]}}},\n",
       " 'W99-0613': {1: {'Citing Article': 'N01-1023',\n",
       "   'Citation Text': 'Co-Training has been used before in applications like word-sense disambiguation (Yarowsky, 1995), web-page classification (Blum and Mitchell, 1998) and named entity identification (Collins and Singer, 1999)',\n",
       "   'CTS': {'aakansha': [9], 'swastika': [9], 'sweta': [121], 'vardha': [9]}},\n",
       "  2: {'Citing Article': 'N01-1023',\n",
       "   'Citation Text': '(Collins and Singer, 1999) further extend the use of classifiers that have mutual constraints by adding terms to AdaBoost which force the classifiers to agree (called Co Boosting)',\n",
       "   'CTS': {'aakansha': [36],\n",
       "    'swastika': [159],\n",
       "    'sweta': [252],\n",
       "    'vardha': [35]}},\n",
       "  3: {'Citing Article': 'W03-1509',\n",
       "   'Citation Text': 'Recent methods for English NER focus on machine-learning algorithms such as DL-CoTrain, CoBoost [Collins and Singer 1999], HMM [Daniel M. Bikel 1997], maximum entropy model [Borthwick, et al 1999] and so on',\n",
       "   'CTS': {'aakansha': [137]}},\n",
       "  4: {'Citing Article': 'C02-1154',\n",
       "   'Citation Text': 'DL-CoTrain, (Collins and Singer, 1999), learns capitalized proper name NEs from a syntactically analyzed corpus',\n",
       "   'CTS': {'aakansha': [79]}},\n",
       "  5: {'Citing Article': 'C02-1154',\n",
       "   'Citation Text': '(Collins and Singer, 1999) also makes use of competing categories (person, organization, and location), which cover 96% of all the instances it set out to classify',\n",
       "   'CTS': {'aakansha': [10], 'swastika': [91], 'sweta': [91], 'vardha': []}},\n",
       "  6: {'Citing Article': 'W06-2204',\n",
       "   'Citation Text': 'In (Collins and Singer, 1999) Collins and Singer show that unlabeled data can be used to reduce the level of supervision required for named entity classification',\n",
       "   'CTS': {'aakansha': [18]}},\n",
       "  8: {'Citing Article': 'W03-1022',\n",
       "   'Citation Text': 'Collins and Singer (1999) for example report that 88% of the named entities occurring in their data set belong to these three categories (Collins and Singer, 1999)',\n",
       "   'CTS': {'aakansha': [236, 237]}},\n",
       "  9: {'Citing Article': 'E09-1018',\n",
       "   'Citation Text': 'While EM has worked quite well for a few tasks, notably machine translations (starting with the IBM models 1-5 (Brown et al, 1993), it has not had success in most others, such as part-of-speech tagging (Merialdo, 1991), named-entity recognition (Collinsand Singer, 1999) and context-free-grammar induction (numerous attempts, too many to mention)',\n",
       "   'CTS': {'aakansha': [9, 10]}},\n",
       "  11: {'Citing Article': 'W07-1712',\n",
       "   'Citation Text': 'In addition, we would also like to explore the semi-supervised techniques such as co-training and self-training (Collins and Singer, 1999)',\n",
       "   'CTS': {'aakansha': [137, 39]}},\n",
       "  12: {'Citing Article': 'W09-2208',\n",
       "   'Citation Text': \"Collins et al (Collins and Singer, 1999) proposed two algorithms for NER by modifying Yarowsky's method (Yarowsky, 1995) and the framework suggested by (Blum and Mitchell, 1998)\",\n",
       "   'CTS': {'aakansha': [26, 27]}},\n",
       "  13: {'Citing Article': 'W06-2207',\n",
       "   'Citation Text': 'This approach was shown to perform well on real-world natural language problems (Collins and Singer, 1999)',\n",
       "   'CTS': {'aakansha': [18]}},\n",
       "  15: {'Citing Article': 'W06-2207',\n",
       "   'Citation Text': '(6) Similarly to (Collins and Singer, 1999) we used T= 0.95 for all experiments reported here',\n",
       "   'CTS': {'aakansha': [85]}},\n",
       "  16: {'Citing Article': 'P12-1065',\n",
       "   'Citation Text': 'We use Collins and Singer (1999) for our exact specification of Yarowsky',\n",
       "   'CTS': {'aakansha': [8, 9]}},\n",
       "  7: {'Citing Article': 'W06-2204',\n",
       "   'Citation Text': 'In (Collins and Singer, 1999) Collins and Singer show that unlabeled data can be used to reduce the level of supervision required for named entity classification',\n",
       "   'CTS': {'swastika': [250], 'sweta': [250], 'vardha': [8]}},\n",
       "  10: {'Citing Article': 'W03-1022',\n",
       "   'Citation Text': 'Collins and Singer (1999) for example report that 88% of the named entities occurring in their data set belong to these three categories (Collins and Singer, 1999)',\n",
       "   'CTS': {'swastika': [213], 'sweta': [202], 'vardha': [236]}},\n",
       "  17: {'Citing Article': 'W06-2207',\n",
       "   'Citation Text': 'This criterion was used in a lightly-supervised NE recognizer (Collins and Singer, 1999)',\n",
       "   'CTS': {'swastika': [], 'sweta': [172], 'vardha': [32]}},\n",
       "  18: {'Citing Article': 'W06-2207',\n",
       "   'Citation Text': '(6) Similarly to (Collins and Singer, 1999) we used T= 0.95 for all experiments reported here',\n",
       "   'CTS': {'swastika': [85], 'sweta': [85], 'vardha': []}},\n",
       "  19: {'Citing Article': 'P12-1065',\n",
       "   'Citation Text': 'We use Collins and Singer (1999) for our exact specification of Yarowsky',\n",
       "   'CTS': {'swastika': [95], 'sweta': [], 'vardha': [47]}},\n",
       "  20: {'Citing Article': 'P12-1065',\n",
       "   'Citation Text': 'This is not clearly specified in Collins and Singer (1999), but is used for DL-CoTrain in the same paper',\n",
       "   'CTS': {'swastika': [213], 'sweta': [214], 'vardha': [127]}}},\n",
       " 'W99-0623': {1: {'Citing Article': 'A00-2005',\n",
       "   'Citation Text': 'Henderson and Brill (1999) showed that independent human research efforts produce parsers that can be combined for an overall boost in accuracy',\n",
       "   'CTS': {'swastika': [85], 'sweta': [144], 'vardha': [85]}},\n",
       "  2: {'Citing Article': 'A00-2005',\n",
       "   'Citation Text': 'Given a novel sentence Stest E Ctest, combine the collection of hypotheses ti = fi(Stest) using the unweighted constituent voting scheme of Henderson and Brill (1999)',\n",
       "   'CTS': {'swastika': [120], 'sweta': [125], 'vardha': [117]}},\n",
       "  4: {'Citing Article': 'N10-1091',\n",
       "   'Citation Text': '(Henderson and Brill, 1999) used a similar framework in the context of constituent parsing and only three base parsers',\n",
       "   'CTS': {'swastika': [25], 'sweta': [125], 'vardha': [72]}},\n",
       "  5: {'Citing Article': 'W05-1518',\n",
       "   'Citation Text': 'A successful application of voting and of a stacked classifier to constituent parsing followed in (Henderson and Brill, 1999)',\n",
       "   'CTS': {'swastika': [120], 'sweta': [48], 'vardha': [120]}},\n",
       "  6: {'Citing Article': 'W05-1518',\n",
       "   'Citation Text': \"This approach roughly corresponds to (Henderson and Brill, 1999)'s Naive Bayes parse hybridization\",\n",
       "   'CTS': {'swastika': [38], 'sweta': [139], 'vardha': [139]}},\n",
       "  7: {'Citing Article': 'W05-1518',\n",
       "   'Citation Text': 'Henderson and Brill (1999) also reported that context did not help them to outperform simple voting',\n",
       "   'CTS': {'swastika': [91], 'sweta': [134], 'vardha': [84]}},\n",
       "  8: {'Citing Article': 'W05-1518',\n",
       "   'Citation Text': \"(Henderson and Brill, 1999) improved their best parser's F-measure of 89.7 to 91.3, using their naive Bayes voting on the Penn TreeBank constituent structures (16% error reduction)\",\n",
       "   'CTS': {'swastika': [120], 'sweta': [38], 'vardha': [76]}},\n",
       "  10: {'Citing Article': 'P01-1005',\n",
       "   'Citation Text': 'Voting has proven to be an effective technique for improving classifier accuracy for many applications, including part-of-speech tagging (van Halteren, et al 1998), parsing (Henderson and Brill, 1999), and word sense disambiguation (Pederson, 2000)',\n",
       "   'CTS': {'swastika': [120], 'sweta': [120], 'vardha': [38]}},\n",
       "  11: {'Citing Article': 'D09-1161',\n",
       "   'Citation Text': 'Regarding the system combination study, Henderson and Brill (1999) propose two parser combination schemes, one that selects an entire tree from one of the parsers, and one that builds a new tree by selecting constituents suggested by the initial trees',\n",
       "   'CTS': {'swastika': [139], 'sweta': [139], 'vardha': [25]}},\n",
       "  12: {'Citing Article': 'D09-1161',\n",
       "   'Citation Text': 'Henderson and Brill (1999) combine three parsers and obtained an F1 score of 90.6, which is better than the score of 88.6 obtained by the best individual parser as reported in their paper',\n",
       "   'CTS': {'swastika': [25], 'sweta': [13], 'vardha': [72]}},\n",
       "  13: {'Citing Article': 'D09-1161',\n",
       "   'Citation Text': 'Besides the two model scores, we also adopt constituent count as an additional feature in spired by (Henderson and Brill 1999) and (Sagae and Lavie 2006)',\n",
       "   'CTS': {'swastika': [103], 'sweta': [108], 'vardha': [87]}},\n",
       "  14: {'Citing Article': 'N06-2033',\n",
       "   'Citation Text': 'Henderson and Brill (1999) proposed two parser combination schemes, one that picks an entire tree from one of the parsers, and one that, like ours, builds a new tree from constituents from the initial trees',\n",
       "   'CTS': {'swastika': [139], 'sweta': [139], 'vardha': [51]}},\n",
       "  15: {'Citing Article': 'N09-2064',\n",
       "   'Citation Text': '(Henderson and Brill, 1999) perform parse selection by maximizing the expected precision of the selected parse with respect to the set of parses being combined',\n",
       "   'CTS': {'swastika': [70], 'sweta': [98], 'vardha': [79]}},\n",
       "  16: {'Citing Article': 'N09-2064',\n",
       "   'Citation Text': '(Henderson and Brill, 1999) and (Sagae and Lavie, 2006) propose methods for parse hybridization by recombining constituents',\n",
       "   'CTS': {'swastika': [140], 'sweta': [27], 'vardha': [27]}},\n",
       "  17: {'Citing Article': 'N09-2064',\n",
       "   'Citation Text': 'Second, the parse selection method of (Henderson and Brill, 1999) selects the parse with maximum expected precision; here, we present an efficient, linear-time algorithm for selecting the parse with maximum expected f-score within the Mini mum Bayes Risk (MBR) framework',\n",
       "   'CTS': {'swastika': [70], 'sweta': [80, 81, 82], 'vardha': [77]}},\n",
       "  18: {'Citing Article': 'P09-1065',\n",
       "   'Citation Text': 'System combination has benefited various NLP tasks in recent years, such as products-of-experts (e.g., (Smith and Eisner, 2005)) and ensemble based parsing (e.g., (Henderson and Brill, 1999))',\n",
       "   'CTS': {'swastika': [85], 'sweta': [49], 'vardha': []}},\n",
       "  20: {'Citing Article': 'C10-1151',\n",
       "   'Citation Text': 'Henderson and Brill (1999) performs parse selection by maximizing the expected precision of selected parse with respect to the set of parses to be combined',\n",
       "   'CTS': {'swastika': [70], 'sweta': [98], 'vardha': [116]}},\n",
       "  19: {'Citing Article': 'N03-1004',\n",
       "   'Citation Text': 'In NLP, such methods have been applied to tasks such as POS tagging (Brill and Wu, 1998), word sense disambiguation (Pedersen, 2000), parsing (Henderson and Brill, 1999), and machine translation (Frederking and Nirenburg, 1994)',\n",
       "   'CTS': {'sweta': [11], 'vardha': [11]}}}}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ed87dcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cts2feature(cts,length):\n",
    "    feature = [0] * length\n",
    "    for idx in cts:\n",
    "        feature[idx] = 1\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3a7dd4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotators = list(annotators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ba963d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aakansha vardha 0.15304907018520342\n",
      "aakansha sweta 0.10517203569560496\n",
      "aakansha swastika 0.19300604363524587\n",
      "vardha akanksha 0.17632965979875415\n",
      "vardha sweta 0.15167721193908912\n",
      "vardha swastika 0.17373271035953186\n",
      "akanksha sweta 0.1719976567076743\n",
      "sweta swastika 0.15432271735922465\n"
     ]
    }
   ],
   "source": [
    "agreements = []\n",
    "for i in range(len(annotators)):\n",
    "    for j in range(i+1, len(annotators)):\n",
    "        annotator1 = annotators[i]\n",
    "        annotator2 = annotators[j]\n",
    "        \n",
    "        annotator1_feature = []\n",
    "        annotator2_feature = []\n",
    "        for paper_name, citations in all_annotations.items():\n",
    "            length = len(full_texts[paper_name])\n",
    "            for citation_id, citation in citations.items():\n",
    "                if annotator1 in citation[\"CTS\"] and annotator2 in citation[\"CTS\"]:\n",
    "                    annotator1_feature.extend(cts2feature(citation[\"CTS\"][annotator1],length))\n",
    "                    annotator2_feature.extend(cts2feature(citation[\"CTS\"][annotator2],length))\n",
    "        if len(annotator1_feature) > 0:\n",
    "            kappa = cohen_kappa_score(annotator1_feature, annotator2_feature)\n",
    "            agreements.append(kappa)\n",
    "            print(annotator1, annotator2, kappa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "88922232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15991088821004104"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(agreements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8990482",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 20/20 [00:49<00:00,  2.47s/it]\n"
     ]
    }
   ],
   "source": [
    "annotations = {}\n",
    "for paper, this_paper in tqdm(all_annotations.items()):\n",
    "    reference_full_text = full_texts[paper]\n",
    "    for citance_id, this_citance in this_paper.items():\n",
    "        example_id = paper + \"_\" + str(citance_id)\n",
    "        offsets = []\n",
    "        for annotator, offset in this_citance[\"CTS\"].items():\n",
    "            offsets.extend(offset)\n",
    "        offsets = set(offsets)\n",
    "        query = remove_stop_words(this_citance[\"Citation Text\"]).lower()\n",
    "        similarities = []\n",
    "        for si, sent in reference_full_text.items():\n",
    "            scores = scorer.score(query, sent[\"no_stop\"])\n",
    "            performance = (scores[\"rouge1\"].recall + scores[\"rouge2\"].recall) / 2\n",
    "            similarities.append((si, performance))\n",
    "        sorted_similarity = sorted(similarities, key=lambda x: x[1], reverse=True)\n",
    "        ranked_si = [t[0] for t in sorted_similarity]\n",
    "        annotations[example_id] = {\n",
    "            \"annotation\": offsets,\n",
    "            \"rankings\": ranked_si,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78d1532b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 20/20 [00:00<00:00, 33825.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191\n",
      "113\n",
      "176\n",
      "200\n",
      "154\n",
      "147\n",
      "415\n",
      "194\n",
      "114\n",
      "203\n",
      "198\n",
      "142\n",
      "175\n",
      "165\n",
      "233\n",
      "111\n",
      "179\n",
      "288\n",
      "257\n",
      "149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for paper, this_paper in tqdm(all_annotations.items()):\n",
    "    reference_full_text = full_texts[paper]\n",
    "    print(len(reference_full_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "695cc4fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.260989010989011 0.10474090407938258 0.14948859166011014\n",
      "2 0.2261904761904762 0.13616317530319735 0.16999311768754302\n",
      "3 0.20467032967032966 0.16427783902976847 0.18226299694189602\n",
      "4 0.18626373626373627 0.1868798235942668 0.18657127132636211\n",
      "5 0.17435897435897435 0.20992282249173097 0.19049524762381193\n",
      "6 0.16457352171637885 0.23116501286291805 0.1922665443985939\n",
      "7 0.15600470957613816 0.25043313907702003 0.19224956169518168\n",
      "8 0.14888583638583638 0.26888092613009923 0.19165029469548134\n",
      "9 0.14236874236874236 0.28567928457674874 0.19003381819663445\n",
      "10 0.13621378621378621 0.30066152149944875 0.18748710897215537\n",
      "11 0.13066100566100566 0.31462363435902574 0.18464162818740623\n",
      "12 0.12584530853761622 0.3282800441014333 0.1819431714023831\n",
      "13 0.1216036710542205 0.341616487151217 0.17936101525102974\n",
      "14 0.11768707482993197 0.3542290124429044 0.17667622451785225\n",
      "15 0.11414835164835165 0.3664829106945976 0.17407698350353498\n",
      "16 0.11085972850678733 0.37816979051819183 0.17145713571607096\n",
      "17 0.1077713136536666 0.38926000389130294 0.16880651376017777\n",
      "18 0.10492577597840756 0.40003675119441384 0.1662466590301642\n",
      "19 0.10231347599768652 0.4106075552718621 0.1638095679048071\n",
      "20 0.0999215070643642 0.421058434399118 0.16151406216959188\n",
      "21 0.09765234765234765 0.4310915104740904 0.15923437181836692\n",
      "22 0.09546974764366069 0.4406134108449434 0.1569355443300073\n",
      "23 0.09344640866379997 0.45002636498729687 0.1547578817226458\n",
      "24 0.09152930402930402 0.45916023520764426 0.15263270417201147\n",
      "25 0.08971259509721048 0.46804851157662625 0.15056570313885442\n",
      "26 0.08802949187564572 0.4769315579679417 0.14862632643082738\n",
      "27 0.08642217570789 0.4855649475274613 0.14672910458351074\n",
      "28 0.08488740323715693 0.49397542920144905 0.1448781614505139\n",
      "29 0.08337122647467475 0.5018819146105007 0.1429894444955942\n",
      "30 0.08190358029067707 0.5094818081587652 0.14112078179874793\n",
      "31 0.0805122297057781 0.5169826083863854 0.13932646733217996\n",
      "32 0.07916562604062605 0.5242213340683572 0.13755786199913206\n",
      "33 0.07788290141231317 0.5313554508703351 0.13585324705832105\n",
      "34 0.07665527749561363 0.5383617614631299 0.13420203865523123\n",
      "35 0.07546659689516833 0.5451567175933217 0.13258000881006646\n",
      "36 0.0743036993036993 0.5516660541467597 0.13096744172519595\n",
      "37 0.07317931002141528 0.5580023242647278 0.12938977581697764\n",
      "38 0.07207738280612774 0.5640631346834561 0.12782142739735033\n",
      "39 0.07100943927867005 0.569954485059226 0.12628526149962574\n",
      "40 0.06996448673277941 0.575606394707828 0.12476401003704145\n"
     ]
    }
   ],
   "source": [
    "hit_all = 0\n",
    "total_all = 0\n",
    "total_proposed = 0\n",
    "recall_all = []\n",
    "f1_all = []\n",
    "precision_all = []\n",
    "for k in range(1,41):\n",
    "    for example, annotation in annotations.items():\n",
    "        prediction = annotation[\"rankings\"][:k]\n",
    "        hit = annotation[\"annotation\"].intersection(set(prediction))\n",
    "        hit_all += len(hit)\n",
    "        total_all += len(annotation[\"annotation\"])\n",
    "        total_proposed += k\n",
    "    recall = hit_all / total_all\n",
    "    precision = hit_all / total_proposed\n",
    "    f1 = 2 * precision * recall / (recall + precision)\n",
    "    print(k, precision, recall, f1)\n",
    "    recall_all.append(recall)\n",
    "    precision_all.append(precision)\n",
    "    f1_all.append(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6df1c519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.260989010989011 0.10474090407938258\n",
      "2 0.32005494505494503 0.13616317530319735\n",
      "3 0.3708791208791209 0.16427783902976847\n",
      "4 0.4100274725274725 0.1868798235942668\n",
      "5 0.4472527472527473 0.20992282249173097\n",
      "6 0.47893772893772896 0.23116501286291805\n",
      "7 0.5070643642072213 0.25043313907702003\n",
      "8 0.5336538461538461 0.26888092613009923\n",
      "9 0.5567765567765568 0.28567928457674874\n",
      "10 0.5766483516483516 0.30066152149944875\n",
      "11 0.5951548451548452 0.31462363435902574\n",
      "12 0.6130952380952381 0.3282800441014333\n",
      "13 0.6297548605240912 0.341616487151217\n",
      "14 0.6452119309262166 0.3542290124429044\n",
      "15 0.6593406593406593 0.3664829106945976\n",
      "16 0.6723901098901099 0.37816979051819183\n",
      "17 0.6840659340659341 0.38926000389130294\n",
      "18 0.6949023199023199 0.40003675119441384\n",
      "19 0.7050318102949682 0.4106075552718621\n",
      "20 0.7142857142857143 0.421058434399118\n",
      "21 0.7227891156462585 0.4310915104740904\n",
      "22 0.7307692307692307 0.4406134108449434\n",
      "23 0.7386526516961299 0.45002636498729687\n",
      "24 0.7461080586080586 0.45916023520764426\n",
      "25 0.7530769230769231 0.46804851157662625\n",
      "26 0.7596153846153846 0.4769315579679417\n",
      "27 0.7658730158730159 0.4855649475274613\n",
      "28 0.7716836734693877 0.49397542920144905\n",
      "29 0.7770935960591133 0.5018819146105007\n",
      "30 0.7822344322344322 0.5094818081587652\n",
      "31 0.7873094647288196 0.5169826083863854\n",
      "32 0.7920673076923077 0.5242213340683572\n",
      "33 0.7965367965367965 0.5313554508703351\n",
      "34 0.8008241758241759 0.5383617614631299\n",
      "35 0.804945054945055 0.5451567175933217\n",
      "36 0.8088369963369964 0.5516660541467597\n",
      "37 0.8125185625185625 0.5580023242647278\n",
      "38 0.8160063620589937 0.5640631346834561\n",
      "39 0.8193857424626655 0.569954485059226\n",
      "40 0.8225961538461538 0.575606394707828\n"
     ]
    }
   ],
   "source": [
    "hit_any = 0\n",
    "total_any = 0\n",
    "hit_all = 0\n",
    "total_all = 0\n",
    "recall_any = []\n",
    "recall_all = []\n",
    "for k in range(1,41):\n",
    "    for example, annotation in annotations.items():\n",
    "        prediction = annotation[\"rankings\"][:k]\n",
    "        hit = annotation[\"annotation\"].intersection(set(prediction))\n",
    "        if len(hit) > 0:\n",
    "            hit_any += 1\n",
    "        hit_all += len(hit)\n",
    "        total_any += 1\n",
    "        total_all += len(annotation[\"annotation\"])\n",
    "    print(k, hit_any / total_any, hit_all / total_all)\n",
    "    recall_any.append(hit_any / total_any)\n",
    "    recall_all.append(hit_all / total_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2d9dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65a7ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265cfe38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
